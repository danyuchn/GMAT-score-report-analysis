# -*- coding: utf-8 -*- # Ensure UTF-8 encoding for comments/strings
import streamlit as st

# Call set_page_config as the first Streamlit command
st.set_page_config(
    page_title="GMAT æˆç¸¾è¨ºæ–·å¹³å°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

from dotenv import load_dotenv
load_dotenv()

import sys
import os
import io
import pandas as pd
import numpy as np
import logging
import openai
import plotly.graph_objects as go
import datetime

# --- Project Path Setup ---
try:
    app_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(app_dir)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
except NameError:
    # Handle cases where __file__ is not defined (e.g., interactive environments)
    st.warning("Could not automatically determine project root. Assuming modules are available.", icon="âš ï¸")
    project_root = os.getcwd()  # Fallback

# --- Module Imports ---
try:
    # Import custom modules for core logic
    from gmat_diagnosis_app import preprocess_helpers # Ensure the module itself is imported for setup_input_tabs
    # from gmat_diagnosis_app import irt_module as irt # Moved to analysis_orchestrator
    # from gmat_diagnosis_app.irt import probability_correct, item_information, estimate_theta, initialize_question_bank, simulate_cat_exam
    # from gmat_diagnosis_app.diagnostics.v_diagnostic import run_v_diagnosis_processed # Moved
    # from gmat_diagnosis_app.diagnostics.di_diagnostic import run_di_diagnosis_processed # Moved
    # from gmat_diagnosis_app.diagnostics.q_diagnostic import diagnose_q # Moved
    
    # Import our modularized components
    from gmat_diagnosis_app.constants.config import (
        SUBJECTS, # Retained: Used in main for iterating tabs and processing
        # MAX_FILE_SIZE_MB, MAX_FILE_SIZE_BYTES, # Removed: Likely used within setup_input_tabs
        # BANK_SIZE, RANDOM_SEED, SUBJECT_SIM_PARAMS, FINAL_DIAGNOSIS_INPUT_COLS, # Removed: Likely used in analysis_orchestrator or deeper
        BASE_RENAME_MAP # Retained: Used in main for sample data processing
        # REQUIRED_ORIGINAL_COLS, EXCEL_COLUMN_MAP # Removed: Likely used within setup_input_tabs or preprocess_helpers
    )
    # from gmat_diagnosis_app.constants.thresholds import THRESHOLDS # Removed: Likely used in analysis_orchestrator or deeper
    # from gmat_diagnosis_app.utils.validation import validate_dataframe
    # from gmat_diagnosis_app.utils.data_processing import process_subject_tab
    # from gmat_diagnosis_app.utils.styling import apply_styles
    # from gmat_diagnosis_app.utils.excel_utils import to_excel # Removed
    from gmat_diagnosis_app.services.openai_service import ( # Retained: get_chat_context, get_openai_response might be used by a chat interface if it were called
        # summarize_report_with_openai, generate_ai_consolidated_report, # Removed: Assumed handled by orchestrator/display
        get_chat_context, get_openai_response # Retained cautiously, though display_chat_interface is not called
    )
    # from gmat_diagnosis_app.services.plotting_service import create_theta_plot
    from gmat_diagnosis_app.ui.results_display import display_results # Removed display_subject_results
    # from gmat_diagnosis_app.ui.chat_interface import display_chat_interface # Removed: Not called
    from gmat_diagnosis_app.ui.input_tabs import setup_input_tabs, combine_input_data, display_analysis_button
    from gmat_diagnosis_app.session_manager import init_session_state, reset_session_for_new_upload, ensure_chat_history_persistence
    from gmat_diagnosis_app.analysis_orchestrator import run_analysis # Added import
    from gmat_diagnosis_app.services.csv_data_service import add_gmat_performance_record, GMAT_PERFORMANCE_HEADERS, add_subjective_report_record # Added for CSV export and new function
    
    # Import the new analysis helpers - These are likely used by analysis_orchestrator, not directly here.
    # from gmat_diagnosis_app.analysis_helpers.time_pressure_analyzer import calculate_time_pressure, calculate_and_apply_invalid_logic # Removed
    # from gmat_diagnosis_app.analysis_helpers.simulation_manager import run_simulation, prepare_dataframes_for_diagnosis # Removed
    # from gmat_diagnosis_app.analysis_helpers.diagnosis_manager import run_diagnosis, update_session_state_after_analysis # Removed
    
except ImportError as e:
    st.error(f"å°å…¥æ¨¡çµ„æ™‚å‡ºéŒ¯: {e}. è«‹ç¢ºä¿ç’°å¢ƒè¨­å®šæ­£ç¢ºï¼Œä¸” gmat_diagnosis_app åœ¨ Python è·¯å¾‘ä¸­ã€‚")
    st.stop()

# --- Initialize Column Display Configuration ---
# COLUMN_DISPLAY_CONFIG moved to ui/results_display.py

# --- Session State Functions ---
# init_session_state and reset_session_for_new_upload moved to session_manager.py

# --- Analysis Functions ---
# run_analysis moved to analysis_orchestrator.py

# --- Display Results Function ---
# display_results moved to ui.results_display.py

# Callback function for loading sample data
def load_sample_data_callback():
    """Sets session state for sample data to be pasted into text areas."""
    sample_q_data = """Question	Response Time (Minutes)	Performance	Content Domain	Question Type	Fundamental Skills
1	2.3	Correct	Algebra	REAL	Equal/Unequal/ALG
2	4.8	Correct	Algebra	REAL	Rates/Ratio/Percent
3	1.3	Correct	Arithmetic	REAL	Equal/Unequal/ALG
4	2.2	Incorrect	Arithmetic	REAL	Value/Order/Factors
5	0.8	Correct	Arithmetic	REAL	Rates/Ratio/Percent
6	3.5	Correct	Algebra	REAL	Rates/Ratio/Percent
7	1.5	Correct	Algebra	REAL	Equal/Unequal/ALG
8	1.5	Correct	Arithmetic	REAL	Rates/Ratio/Percent
9	1.3	Correct	Arithmetic	REAL	Counting/Sets/Series/Prob/Stats
10	5.4	Correct	Arithmetic	REAL	Counting/Sets/Series/Prob/Stats
11	2.6	Incorrect	Algebra	PURE	Equal/Unequal/ALG
12	4.3	Correct	Arithmetic	PURE	Rates/Ratio/Percent
13	1.6	Incorrect	Arithmetic	PURE	Counting/Sets/Series/Prob/Stats
14	0.9	Correct	Arithmetic	REAL	Counting/Sets/Series/Prob/Stats
15	0.7	Correct	Algebra	PURE	Value/Order/Factors
16	4.6	Correct	Algebra	PURE	Value/Order/Factors
17	2.1	Correct	Algebra	PURE	Counting/Sets/Series/Prob/Stats
18	0.7	Correct	Arithmetic	PURE	Equal/Unequal/ALG
19	0.7	Correct	Arithmetic	PURE	Rates/Ratio/Percent
20	0.8	Incorrect	Arithmetic	PURE	Value/Order/Factors
21	0.9	Correct	Arithmetic	PURE	Value/Order/Factors"""

    sample_v_data = """Question	Response Time (Minutes)	Performance	Content Domain	Question Type	Fundamental Skills
1	1.5	Correct	N/A	Critical Reasoning	Plan/Construct
2	3.6	Correct	N/A	Critical Reasoning	Plan/Construct
3	3	Correct	N/A	Reading Comprehension	Identify Stated Idea
4	1	Incorrect	N/A	Reading Comprehension	Identify Inferred Idea
5	3.7	Incorrect	N/A	Reading Comprehension	Identify Inferred Idea
6	1.7	Incorrect	N/A	Critical Reasoning	Analysis/Critique
7	2.7	Correct	N/A	Reading Comprehension	Identify Inferred Idea
8	1	Correct	N/A	Reading Comprehension	Identify Stated Idea
9	1.6	Correct	N/A	Reading Comprehension	Identify Inferred Idea
10	2.2	Correct	N/A	Critical Reasoning	Plan/Construct
11	4.4	Correct	N/A	Reading Comprehension	Identify Inferred Idea
12	0.6	Correct	N/A	Reading Comprehension	Identify Stated Idea
13	2.3	Correct	N/A	Reading Comprehension	Identify Inferred Idea
14	0.6	Correct	N/A	Reading Comprehension	Identify Stated Idea
15	2.4	Incorrect	N/A	Critical Reasoning	Analysis/Critique
16	2.3	Incorrect	N/A	Critical Reasoning	Analysis/Critique
17	2.8	Incorrect	N/A	Critical Reasoning	Plan/Construct
18	1.3	Correct	N/A	Critical Reasoning	Analysis/Critique
19	0.7	Correct	N/A	Critical Reasoning	Analysis/Critique
20	1.9	Incorrect	N/A	Critical Reasoning	Analysis/Critique
21	1.4	Incorrect	N/A	Critical Reasoning	Analysis/Critique
22	1	Correct	N/A	Critical Reasoning	Plan/Construct
23	1.2	Incorrect	N/A	Critical Reasoning	Plan/Construct"""

    sample_di_data = """Question	Response Time (Minutes)	Performance	Content Domain	Question Type	Fundamental Skills
1	1.5	Correct	Math Related	Data Sufficiency	N/A
2	1.8	Correct	Math Related	Data Sufficiency	N/A
3	3.1	Correct	Non-Math Related	Two-part analysis	N/A
4	4.2	Correct	Math Related	Multi-source reasoning	N/A
5	1.9	Incorrect	Non-Math Related	Multi-source reasoning	N/A
6	1	Incorrect	Math Related	Multi-source reasoning	N/A
7	3.7	Incorrect	Non-Math Related	Data Sufficiency	N/A
8	2.5	Incorrect	Non-Math Related	Graph and Table	N/A
9	5.9	Correct	Non-Math Related	Two-part analysis	N/A
10	2.7	Incorrect	Math Related	Graph and Table	N/A
11	2.1	Incorrect	Math Related	Data Sufficiency	N/A
12	1.7	Incorrect	Math Related	Data Sufficiency	N/A
13	2.8	Correct	Non-Math Related	Graph and Table	N/A
14	1.5	Incorrect	Math Related	Data Sufficiency	N/A
15	2	Incorrect	Non-Math Related	Graph and Table	N/A
16	1.2	Incorrect	Non-Math Related	Data Sufficiency	N/A
17	0.4	Incorrect	Math Related	Two-part analysis	N/A
18	3.5	Incorrect	Math Related	Graph and Table	N/A
19	0.1	Incorrect	Math Related	Two-part analysis	N/A
20	1.2	Incorrect	Math Related	Graph and Table	N/A"""

    st.session_state.q_paster = sample_q_data
    st.session_state.v_paster = sample_v_data
    st.session_state.di_paster = sample_di_data
    
    if 'example_data_loaded' in st.session_state:
        del st.session_state['example_data_loaded']
    if 'example_data' in st.session_state:
        del st.session_state['example_data']
    
    st.session_state.sample_data_pasted_success = True

# --- Main Application ---
def main():
    """Main application entry point"""
    # è¨­ç½®é é¢é…ç½®
    # st.set_page_config( # This block will be removed
    #     page_title="GMAT æˆç¸¾è¨ºæ–·å¹³å°",
    #     page_icon="ğŸ“Š",
    #     layout="wide",
    #     initial_sidebar_state="expanded"
    # )
    
    # Initialize session state
    init_session_state()
    
    # é¡å¤–ç¢ºä¿èŠå¤©æ­·å²æŒä¹…åŒ–
    ensure_chat_history_persistence()

    # Initialize the success message flag for sample data pasting if it doesn't exist
    if 'sample_data_pasted_success' not in st.session_state:
        st.session_state.sample_data_pasted_success = False
    
    # é é¢æ¨™é¡Œèˆ‡ç°¡ä»‹å€
    col1, col2 = st.columns([5, 1])
    with col1:
        st.title('ğŸ“Š GMAT æˆç¸¾è¨ºæ–·å¹³å° by Dustin')
        st.markdown('é€éæ•¸æ“šåˆ†ææ·±å…¥äº†è§£æ‚¨çš„GMATè¡¨ç¾ï¼Œæ‰¾å‡ºé—œéµæ”¹é€²é»')
    
    # å»ºç«‹ä¸»è¦å°èˆª
    main_tabs = st.tabs(["ğŸ“¥ æ•¸æ“šè¼¸å…¥èˆ‡åˆ†æ", "ğŸ“ˆ çµæœæŸ¥çœ‹"])
    
    with main_tabs[0]:  # æ•¸æ“šè¼¸å…¥èˆ‡åˆ†ææ¨™ç±¤é 
        # ç°¡çŸ­ä½¿ç”¨æŒ‡å¼•ï¼ˆæ ¸å¿ƒæ­¥é©Ÿï¼‰
        with st.expander("å¿«é€Ÿä½¿ç”¨æŒ‡å— ğŸ‘‰", expanded=False):
            st.markdown("""
            1. **æº–å‚™æ•¸æ“š**: ç¢ºä¿æœ‰Quantitativeã€Verbalå’ŒData Insightsä¸‰ç§‘ç›®çš„æ•¸æ“š
            2. **è¼¸å…¥æ•¸æ“š**: åœ¨ä¸‹æ–¹å››å€‹æ¨™ç±¤ä¸­åˆ†åˆ¥ä¸Šå‚³æˆ–è²¼ä¸Šæ•¸æ“šï¼Œä»¥åŠåœ¨Totalé ç±¤ä¸­èª¿æ•´åˆ†æ•¸
            3. **æª¢æŸ¥é è¦½**: ç¢ºèªæ•¸æ“šæ­£ç¢ºä¸¦æ¨™è¨˜ç„¡æ•ˆé¡Œç›®ï¼ˆæ™‚é–“å£“åŠ›ä¸‹å€‰ä¿ƒåšé¡Œæˆ–çŒœé¡Œï¼‰
            4. **è¨­å®šåƒæ•¸**: åœ¨å´é‚Šæ¬„èª¿æ•´åˆ†æåƒæ•¸ï¼ˆå¯é¸ï¼‰
            5. **é–‹å§‹åˆ†æ**: é»æ“Šç´…è‰²åˆ†ææŒ‰éˆ•
            """)
            
        # --- Disclaimer & Tutorial Links ---
        disclaimer_warning = st.expander("é‡è¦è²æ˜èˆ‡ä½¿ç”¨æ¢æ¬¾ï¼ˆä½¿ç”¨å³ä»£è¡¨åŒæ„ï¼‰", expanded=False)
        with disclaimer_warning:
            st.markdown("""
            ### è«‹ä»”ç´°é–±è®€ä»¥ä¸‹èªªæ˜ï¼š

            æœ¬åˆ†æå·¥å…·æä¾›çš„æ˜¯åŸºæ–¼æ‚¨è¼¸å…¥æ•¸æ“šçš„ç´”é‡åŒ–åˆ†æã€‚åˆ†æçš„æº–ç¢ºæ€§é«˜åº¦ä¾è³´æ‚¨æ‰€è¼¸å…¥æ•¸æ“šçš„å®Œæ•´æ€§èˆ‡æ­£ç¢ºæ€§ã€‚æœ¬å·¥å…·æ¡ç”¨é è¨­åƒæ•¸èˆ‡æ¨™æº–åŒ–è¨ºæ–·é‚è¼¯é€²è¡Œé‹ç®—ï¼Œå…¶ä¸­ï¼š

            1.  **é¡Œç›®é›£åº¦å€¼**ï¼šå ±å‘Šä¸­æ‰€ä½¿ç”¨çš„é¡Œç›®é›£åº¦æ•¸æ“šæ˜¯åŸºæ–¼å…§éƒ¨æ¨¡å‹çš„ IRT æ¨¡æ“¬ä¼°è¨ˆå€¼ï¼Œå…¶ç›®çš„æ˜¯ç‚ºäº†åœ¨æœ¬åˆ†ææ¡†æ¶å…§é€²è¡Œç›¸å°æ¯”è¼ƒèˆ‡è¨ºæ–·ï¼Œä¸¦ä¸ä»£è¡¨ GMAT å®˜æ–¹è€ƒè©¦çš„çœŸå¯¦é¡Œç›®é›£åº¦ã€‚
            2.  **æ•¸æ“šç¯©é¸**ï¼šåˆ†æéç¨‹å¯èƒ½å·²æ ¹æ“šè¦å‰‡ï¼ˆä¾‹å¦‚ï¼šä½œç­”æ™‚é–“ç•°å¸¸ç­‰ï¼‰è‡ªå‹•ç¯©é¸éƒ¨åˆ†è¢«åˆ¤å®šç‚ºç„¡æ•ˆçš„æ•¸æ“šé»ã€‚

            å› æ­¤ï¼Œæœ¬å ±å‘Šç”¢å‡ºçš„æ‰€æœ‰è¨ºæ–·æ¨™ç±¤ã€åˆ†ææ´è¦‹èˆ‡å»ºè­°è¡Œå‹•ï¼Œå‡ç‚ºé‡åŒ–æ•¸æ“šåˆ†æçš„åˆæ­¥çµæœï¼Œåƒ…ä¾›åƒè€ƒï¼Œä¸èƒ½å®Œå…¨å–ä»£å¯¦éš›æƒ…æ³çš„åˆ¤æ–·ã€‚

            æˆ‘å€‘å¼·çƒˆå»ºè­°æ‚¨å°‡æ­¤é‡åŒ–å ±å‘Šä½œç‚ºè¼”åŠ©å·¥å…·ï¼Œä¸¦èˆ‡ç¶“é©—è±å¯Œçš„ GMAT æ•™å¸«æˆ–å°ˆæ¥­é¡§å•ä¸€åŒæª¢è¦–ã€‚é€éå°ˆæ¥­äººå£«é€²ä¸€æ­¥çš„ã€Œè³ªåŒ–åˆ†æã€ï¼ˆä¾‹å¦‚ï¼šæ¢è¨å…·é«”éŒ¯èª¤æ€è·¯ã€è§£é¡Œç¿’æ…£ã€å¿ƒæ…‹å½±éŸ¿ç­‰ï¼‰ï¼Œæ‰èƒ½æ›´æ·±å…¥ã€æº–ç¢ºåœ°è§£è®€æ‚¨çš„è¡¨ç¾ï¼Œæ‰¾å‡ºæ ¹æœ¬å•é¡Œï¼Œä¸¦åˆ¶å®šæœ€æœ‰æ•ˆçš„å€‹äººåŒ–å­¸ç¿’èˆ‡å‚™è€ƒç­–ç•¥ã€‚

            ---

            ### æ•¸æ“šä½¿ç”¨èˆ‡åé¥‹ï¼š

            *   **æ•¸æ“šæ”¶é›†åŒæ„**ï¼šç•¶æ‚¨ä½¿ç”¨æœ¬å·¥å…·ä¸¦ä¸Šå‚³æ‚¨çš„ GMAT æˆç¸¾å–®æ•¸æ“šæ™‚ï¼Œå³è¡¨ç¤ºæ‚¨ç†è§£ä¸¦åŒæ„æˆæ¬Šé–‹ç™¼è€…ï¼ˆæˆ‘ï¼‰æ”¶é›†é€™äº›æ•¸æ“šï¼Œç”¨æ–¼å¾ŒçºŒæ¨¡å‹å„ªåŒ–ã€å­¸è¡“ç ”ç©¶æˆ–å…¶ä»–ç›¸é—œåˆ†æç›®çš„ã€‚
            *   **å»è­˜åˆ¥åŒ–è²¬ä»»**ï¼šç‚ºä¿è­·æ‚¨çš„å€‹äººéš±ç§ï¼Œè«‹å‹™å¿…åœ¨ä¸Šå‚³å‰ï¼Œä»”ç´°æª¢æŸ¥ä¸¦æ‰‹å‹•å»é™¤æ‚¨æˆç¸¾å–®æ•¸æ“šä¸­çš„æ‰€æœ‰å€‹äººèº«ä»½è­˜åˆ¥è³‡è¨Šï¼ˆä¾‹å¦‚ï¼šå§“åã€è€ƒç”Ÿ IDã€è€ƒè©¦ä¸­å¿ƒã€é›»å­éƒµä»¶åœ°å€ç­‰ï¼‰ã€‚ç¢ºä¿æ‚¨ä¸Šå‚³çš„æ•¸æ“šå·²ç„¡æ³•è¿½æº¯åˆ°æ‚¨å€‹äººã€‚è«‹è¬¹æ…æ“ä½œã€‚
            *   **å•é¡Œåé¥‹**ï¼šæ­¡è¿æ‚¨é€é GitHub Issues æäº¤ä½¿ç”¨åé¥‹ã€ç™¼ç¾çš„å•é¡Œæˆ–å»ºè­°ã€‚è«‹è‡³ï¼šhttps://github.com/danyuchn/GMAT-score-report-analysis/issues
            """)
            
        tutorial_help = st.expander("å®Œæ•´ä½¿ç”¨èªªæ˜", expanded=False)
        with tutorial_help:
            st.markdown("""
            **GMAT æˆç¸¾è¨ºæ–·å¹³å°ä½¿ç”¨èªªæ˜**

            **1. æ­¡è¿ï¼æœ¬å·¥å…·èƒ½åšä»€éº¼ï¼Ÿ**

            æ­¡è¿ä½¿ç”¨ GMAT æˆç¸¾è¨ºæ–·å¹³å°ï¼é€™å€‹å·¥å…·æ—¨åœ¨å¹«åŠ© GMAT è€ƒç”Ÿå’Œæ•™å­¸è€…ï¼š

            - **è¶…è¶Šå–®ç´”åˆ†æ•¸ï¼š** ä¸åªçœ‹å°éŒ¯ï¼Œæ›´æ·±å…¥åˆ†ææ‚¨åœ¨ GMAT å„ç§‘ç›® (Quantitative, Verbal, Data Insights) è¡¨ç¾èƒŒå¾Œçš„æ ¹æœ¬åŸå› ã€‚
            - **æ‰¾å‡ºå¼±é»æ¨¡å¼ï¼š** è­˜åˆ¥æ‚¨åœ¨ç‰¹å®šé¡Œå‹ã€çŸ¥è­˜é»æˆ–æŠ€èƒ½ä¸Šçš„éŒ¯èª¤æ¨¡å¼ã€æ™‚é–“ç®¡ç†å•é¡Œæˆ–ä¸ç©©å®šçš„æ¦‚å¿µæŒæ¡ï¼ˆä¾‹å¦‚ Special Focus Errors, SFEï¼‰ã€‚
            - **ç²å¾—å€‹äººåŒ–å»ºè­°ï¼š** æ ¹æ“šè¨ºæ–·çµæœï¼Œæä¾›å…·é«”çš„ç·´ç¿’æ–¹å‘ï¼ŒåŒ…æ‹¬å»ºè­°çš„ç·´ç¿’é›£åº¦å’Œèµ·å§‹æ™‚é–“é™åˆ¶ã€‚
            - **æå‡å‚™è€ƒæ•ˆç‡ï¼š** è®“æ‚¨çš„ç·´ç¿’æ›´æœ‰é‡å°æ€§ï¼ŒæŠŠæ™‚é–“èŠ±åœ¨æœ€éœ€è¦åŠ å¼·çš„åœ°æ–¹ã€‚

            **2. é–‹å§‹ä¹‹å‰ï¼šæº–å‚™æ‚¨çš„æˆç¸¾å–®æ•¸æ“š**

            **ã€Œæ•¸æ“šå“è³ªæ˜¯è¨ºæ–·æº–ç¢ºçš„åŸºçŸ³ï¼ã€** è«‹å‹™å¿…æº–å‚™ç¬¦åˆæ ¼å¼è¦æ±‚çš„æ•¸æ“šã€‚

            - **æ•¸æ“šä¾†æºï¼š** æ‚¨å¯ä»¥ä½¿ç”¨å®˜æ–¹å¢å¼·ç‰ˆæˆç¸¾å–® (ESR)ã€å®˜æ–¹ç·´ç¿’ (Official Practice Exams)ã€ç¬¬ä¸‰æ–¹æ¨¡è€ƒå¹³å°ï¼Œæˆ–æ‚¨è‡ªå·±è¨˜éŒ„çš„ç·´ç¿’æ•¸æ“šï¼Œåªè¦ç¬¦åˆä»¥ä¸‹æ ¼å¼å³å¯ã€‚
            - **æ ¼å¼è¦æ±‚ï¼š**
                - éœ€è¦**åˆ†åˆ¥**æº–å‚™ Quantitative (Q), Verbal (V), Data Insights (DI) ä¸‰å€‹ç§‘ç›®çš„æ•¸æ“šã€‚
                - æ‚¨å¯ä»¥ä¸Šå‚³ **CSV æª”æ¡ˆ**ï¼ˆæª”æ¡ˆå¤§å°é™åˆ¶ 1MBï¼‰æˆ–ç›´æ¥å¾ **Excel/è¡¨æ ¼** è¤‡è£½æ•¸æ“šä¸¦è²¼ä¸Šã€‚
            - **å¿…è¦æ¬„ä½ï¼ˆæ¬„ä½æ¨™é¡Œé ˆå®Œå…¨ç¬¦åˆï¼Œå¤§å°å¯«/ç©ºæ ¼æ•æ„Ÿï¼‰ï¼š**
                - **é€šç”¨æ¬„ä½:**
                    - `Question`: é¡Œè™Ÿ (å¿…é ˆæ˜¯å¾ 1 é–‹å§‹çš„æ­£æ•´æ•¸)
                    - `Response Time (Minutes)`: æ¯é¡Œä½œç­”æ™‚é–“ (åˆ†é˜ï¼Œå¿…é ˆæ˜¯æ­£æ•¸ï¼Œä¾‹å¦‚ 1.5 æˆ– 2)
                    - `Performance`: ä½œç­”è¡¨ç¾ (å¿…é ˆæ˜¯ 'Correct' æˆ– 'Incorrect' é€™å…©ç¨®å­—ä¸²)
                - **ç§‘ç›®ç‰¹å®šæ¬„ä½:**
                    - `Content Domain` (Q å’Œ DI ç§‘ç›®éœ€è¦):
                        - Q: 'Algebra' æˆ– 'Arithmetic'
                        - DI: 'Math Related' æˆ– 'Non-Math Related'
                    - `Question Type` (Q, V, DI éƒ½éœ€è¦):
                        - Q: 'REAL' æˆ– 'PURE' (æ³¨æ„æ˜¯å¤§å¯«)
                        - V: 'Critical Reasoning' æˆ– 'Reading Comprehension'
                        - DI: 'Data Sufficiency', 'Two-part analysis', 'Multi-source reasoning', 'Graph and Table' (æˆ– 'Graphs and Tables')
                    - `Fundamental Skills` (Q å’Œ V ç§‘ç›®éœ€è¦):
                        - Q: ä¾‹å¦‚ 'Rates/Ratio/Percent', 'Value/Order/Factors', 'Equal/Unequal/ALG', 'Counting/Sets/Series/Prob/Stats' (å…è¨±å¸¸è¦‹çš„è‹±æ–‡åŒç¾©è©æˆ–æ ¼å¼è®Šé«”ï¼Œç³»çµ±æœƒå˜—è©¦è‡ªå‹•æ ¡æ­£)
                        - V: ä¾‹å¦‚ 'Plan/Construct', 'Identify Stated Idea', 'Identify Inferred Idea', 'Analysis/Critique'
            - **é‡è¦ï¼šå»è­˜åˆ¥åŒ– (De-identification)**
                - **åœ¨ä¸Šå‚³æˆ–è²¼ä¸Šæ•¸æ“šå‰ï¼Œè«‹å‹™å¿…ã€å‹™å¿…ã€å‹™å¿…ä»”ç´°æª¢æŸ¥ä¸¦æ‰‹å‹•ç§»é™¤æ‰€æœ‰å¯èƒ½è­˜åˆ¥æ‚¨å€‹äººèº«ä»½çš„è³‡è¨Šï¼** é€™åŒ…æ‹¬ä½†ä¸é™æ–¼ï¼šæ‚¨çš„å§“åã€è€ƒç”Ÿ ID (Candidate ID)ã€è€ƒè©¦ä¸­å¿ƒè³‡è¨Šã€é›»å­éƒµä»¶åœ°å€ç­‰ã€‚
                - æ‚¨å°ç¢ºä¿æ•¸æ“šåŒ¿åè² æœ‰å®Œå…¨è²¬ä»»ã€‚æœ¬å·¥å…·æœƒæ”¶é›†æ‚¨ä¸Šå‚³çš„åŒ¿åæ•¸æ“šç”¨æ–¼æ¨¡å‹æ”¹é€²èˆ‡åˆ†æã€‚

            **3. å¦‚ä½•ä½¿ç”¨æœ¬å·¥å…·ï¼šä¸€æ­¥æ­¥æŒ‡å—**

            - **æ­¥é©Ÿä¸€ï¼šè¼¸å…¥æ•¸æ“š**
                - é»æ“Šä¸Šæ–¹çš„åˆ†é æ¨™ç±¤ï¼Œåˆ†åˆ¥é€²å…¥ Quantitative (Q), Verbal (V), å’Œ Data Insights (DI) çš„è¼¸å…¥å€ã€‚
                - åœ¨æ¯å€‹åˆ†é ä¸­ï¼Œé¸æ“‡ã€Œä¸Šå‚³ CSV æª”æ¡ˆã€æˆ–åœ¨æ–‡å­—æ¡†ä¸­ã€Œè²¼ä¸Š Excel è³‡æ–™ã€ã€‚
                - æˆåŠŸè®€å–å¾Œï¼Œä¸‹æ–¹æœƒå‡ºç¾æ•¸æ“šé è¦½å’Œç·¨è¼¯å™¨ã€‚
            - **æ­¥é©ŸäºŒï¼šé è¦½ã€ç·¨è¼¯èˆ‡æ¨™è¨˜ç„¡æ•ˆæ•¸æ“š**
                - åœ¨æ•¸æ“šç·¨è¼¯å™¨ä¸­ï¼Œæª¢æŸ¥æ‚¨çš„æ•¸æ“šæ˜¯å¦è®€å–æ­£ç¢ºã€‚
                - **é—œéµæ­¥é©Ÿï¼š** å°æ–¼æ‚¨ç¢ºå®šæ˜¯å› æ™‚é–“å£“åŠ›éå¤§ã€å€‰ä¿ƒçŒœæ¸¬ã€åˆ†å¿ƒç­‰åŸå› è€Œã€Œéæ­£å¸¸ä½œç­”ã€çš„é¡Œç›®ï¼Œè«‹å‹¾é¸è©²è¡Œæœ€å·¦å´çš„ **"æ˜¯å¦è‰ç‡åšé¡Œï¼Ÿ (æ‰‹å‹•æ¨™è¨˜)"** æ ¸å–æ–¹å¡Šã€‚ç³»çµ±å¯èƒ½æœƒæ ¹æ“šæ™‚é–“è‡ªå‹•é å…ˆå‹¾é¸éƒ¨åˆ†é¡Œç›®ï¼Œä½†æ‚¨çš„æ‰‹å‹•æ¨™è¨˜æœƒå„ªå…ˆæ¡ç”¨ã€‚
                - æ‚¨ä¹Ÿå¯ä»¥åœ¨ç·¨è¼¯å™¨ä¸­ç›´æ¥ä¿®æ­£æ˜é¡¯çš„æ•¸æ“šéŒ¯èª¤ã€‚
            - **æ­¥é©Ÿä¸‰ï¼šè¨­å®šåˆ†æåƒæ•¸ (å´é‚Šæ¬„)**
                - **IRT æ¨¡æ“¬è¨­å®šï¼š** æ‚¨å¯ä»¥è¨­å®š Q, V, DI å„ç§‘çš„åˆå§‹èƒ½åŠ›ä¼°è¨ˆå€¼ (Theta)ã€‚å¦‚æœæ‚¨ä¸ç¢ºå®šï¼Œ**å»ºè­°ä¿ç•™é è¨­å€¼ 0.0**ã€‚
                - **OpenAI è¨­å®š (é¸ç”¨)ï¼š** å¦‚æœæ‚¨æ“æœ‰ OpenAI API Key ä¸¦å¸Œæœ›ä½¿ç”¨ AI å•ç­”å’Œå ±å‘Šæ•´ç†åŠŸèƒ½ï¼Œè«‹åœ¨æ­¤è¼¸å…¥ã€‚å¦å‰‡è«‹ç•™ç©ºã€‚
            - **æ­¥é©Ÿå››ï¼šé–‹å§‹åˆ†æ**
                - **é‡è¦ï¼š** åªæœ‰ç•¶æ‚¨ç‚º **Q, V, DI ä¸‰å€‹ç§‘ç›®éƒ½æˆåŠŸè¼‰å…¥äº†æœ‰æ•ˆæ•¸æ“š**ï¼ˆé€šéé©—è­‰ä¸”ç„¡éŒ¯èª¤è¨Šæ¯ï¼‰å¾Œï¼Œä¸»é é¢ä¸‹æ–¹çš„ **"é–‹å§‹åˆ†æ"** æŒ‰éˆ•æ‰æœƒè®Šç‚ºå¯ç”¨ç‹€æ…‹ã€‚
                - å¦‚æœæŒ‰éˆ•ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹æ˜¯å¦æœ‰ç´…è‰²éŒ¯èª¤è¨Šæ¯æˆ–ç¼ºå°‘ç§‘ç›®çš„æç¤ºã€‚
                - é»æ“Š "é–‹å§‹åˆ†æ" æŒ‰éˆ•ã€‚é é¢æœƒé¡¯ç¤ºé€²åº¦æ¢å’Œç›®å‰çš„åˆ†ææ­¥é©Ÿã€‚è«‹ç¨å€™ç‰‡åˆ»ã€‚

            **4. ç†è§£æ‚¨çš„è¨ºæ–·å ±å‘Š**

            åˆ†æå®Œæˆå¾Œï¼Œçµæœæœƒé¡¯ç¤ºåœ¨ã€ŒçµæœæŸ¥çœ‹ã€æ¨™ç±¤é ä¸­ï¼š

            - **å„ç§‘ç›®çµæœåˆ†é  (ä¾‹å¦‚ "Q ç§‘çµæœ")ï¼š**
                - **èƒ½åŠ›ä¼°è¨ˆ (Theta) èµ°å‹¢åœ–ï¼š** é¡¯ç¤ºç³»çµ±æ¨¡æ“¬å‡ºçš„æ‚¨çš„èƒ½åŠ›å€¼ (Theta) åœ¨ä½œç­”éç¨‹ä¸­çš„è®ŠåŒ–è¶¨å‹¢ã€‚æ›²ç·šå‘ä¸Šè¡¨ç¤ºèƒ½åŠ›ä¼°è¨ˆå€¼æå‡ã€‚
                - **è¨ºæ–·å ±å‘Š (æ–‡å­—æ‘˜è¦)ï¼š** ä»¥è‡ªç„¶èªè¨€å‘ˆç¾è©³ç´°çš„åˆ†æçµæœï¼ŒåŒ…å«ï¼š
                    - æ•´é«”æ™‚é–“å£“åŠ›è©•ä¼°
                    - å„ç¶­åº¦ï¼ˆå¦‚é¡Œå‹ã€é›£åº¦ã€æŠ€èƒ½ï¼‰çš„è¡¨ç¾æ¦‚è¦½
                    - æ ¸å¿ƒå•é¡Œè¨ºæ–·ï¼ˆéŒ¯èª¤æ¨¡å¼ã€SFE ä¸ç©©å®šé»ç­‰ï¼‰
                    - ç‰¹æ®Šè¡Œç‚ºæ¨¡å¼è§€å¯Ÿï¼ˆå¦‚é–‹é ­æ¶å¿«ã€æ½›åœ¨ç²—å¿ƒç­‰ï¼‰
                    - éœ€è¦éå›ºçš„åŸºç¤çŸ¥è­˜é ˜åŸŸ
                    - å€‹äººåŒ–çš„ç·´ç¿’è¨ˆåŠƒèˆ‡å»ºè­° (åŒ…å«å»ºè­°é›£åº¦ Y å’Œèµ·å§‹æ™‚é–“ Z)
                - **è©³ç´°æ•¸æ“šè¡¨ï¼š** åŒ…å«æ‚¨è¼¸å…¥çš„æ•¸æ“šï¼Œä»¥åŠç³»çµ±è¨ˆç®—å‡ºçš„è¨ºæ–·æ¨™ç±¤ï¼Œä¾‹å¦‚ï¼šæ¨¡æ“¬é›£åº¦ã€æ™‚é–“è¡¨ç¾åˆ†é¡ (å¿«/æ…¢/æ­£å¸¸)ã€æ˜¯å¦ SFEã€æ˜¯å¦è¶…æ™‚ã€æ˜¯å¦è¢«æ¨™è¨˜ç‚ºç„¡æ•ˆç­‰ã€‚è¡¨æ ¼æœ‰é¡è‰²æ¨™ç¤ºï¼šç´…è‰²æ–‡å­—è¡¨ç¤ºç­”éŒ¯ï¼Œè—è‰²æ–‡å­—è¡¨ç¤ºç”¨æ™‚è¶…æ™‚ï¼Œç°è‰²æ–‡å­—è¡¨ç¤ºè©²é¡Œè¢«æ¨™è¨˜ç‚ºç„¡æ•ˆã€‚
                - **ä¸‹è¼‰æŒ‰éˆ•ï¼š** æ‚¨å¯ä»¥å°‡å¸¶æœ‰è¨ºæ–·æ¨™ç±¤çš„è©³ç´°æ•¸æ“šä¸‹è¼‰ç‚º Excel æª”æ¡ˆï¼Œæ–¹ä¾¿é›¢ç·šæŸ¥çœ‹æˆ–èˆ‡æ•™å¸«è¨è«–ã€‚
            - **âœ¨ AI åŒ¯ç¸½å»ºè­°åˆ†é  (è‹¥æ‚¨æä¾›äº† OpenAI Key ä¸”åˆ†ææˆåŠŸ)ï¼š**
                - æ­¤åˆ†é ç”± AI (o4-mini æ¨¡å‹) è‡ªå‹•æ•´ç†ç”Ÿæˆã€‚
                - å®ƒæœƒå¾ Q, V, DI ä¸‰ä»½å ±å‘Šä¸­ï¼Œ**åƒ…æå–ã€Œç·´ç¿’å»ºè­°ã€å’Œã€Œå¾ŒçºŒè¡Œå‹•ã€** é€™å…©å€‹éƒ¨åˆ†çš„å…§å®¹ï¼Œåˆä½µåœ¨ä¸€èµ·ï¼Œæ–¹ä¾¿æ‚¨å¿«é€Ÿæ¦‚è¦½æœ€é‡è¦çš„è¡Œå‹•é …ç›®ã€‚
                - **æ³¨æ„ï¼š** æ­¤ç‚º AI æå–çš„æ‘˜è¦ï¼Œè«‹å‹™å¿…å°ç…§å„ç§‘ç›®çš„å®Œæ•´å ±å‘ŠåŸæ–‡ï¼Œä»¥ç¢ºä¿ç†è§£å®Œæ•´ã€‚

            **5. AI å•ç­”åŠŸèƒ½ (è‹¥æ‚¨æä¾›äº† OpenAI Key)**

            - å¦‚æœåˆ†ææˆåŠŸä¸”æ‚¨è¼¸å…¥äº†æœ‰æ•ˆçš„ OpenAI API Keyï¼Œé é¢æœ€ä¸‹æ–¹æœƒå‡ºç¾ä¸€å€‹**ã€Œèˆ‡ AI å°è©±ã€**çš„èŠå¤©æ¡†ã€‚
            - æ‚¨å¯ä»¥é‡å°**æœ¬æ¬¡ç”Ÿæˆçš„å ±å‘Šå…§å®¹å’Œè©³ç´°æ•¸æ“š**å‘ AI æå•ã€‚ä¾‹å¦‚ï¼š
                - "è«‹è§£é‡‹ä¸€ä¸‹æˆ‘åœ¨ Q ç§‘çš„ SFE éŒ¯èª¤æ˜¯ä»€éº¼æ„æ€ï¼Ÿ"
                - "V ç§‘å ±å‘Šè£¡çš„ 'Slow & Right' å…·é«”æŒ‡å“ªå¹¾é¡Œï¼Ÿ"
                - "å¹«æˆ‘ç¸½çµä¸€ä¸‹ DI ç§‘ç›®çš„ç·´ç¿’å»ºè­°ã€‚"
                - "ç¬¬ 10 é¡Œçš„è¨ºæ–·æ¨™ç±¤æœ‰å“ªäº›ï¼Ÿ"
            - **è«‹æ³¨æ„ï¼š** AI çš„å›ç­”**å®Œå…¨åŸºæ–¼**æœ¬æ¬¡åˆ†æç”¢å‡ºçš„å ±å‘Šå’Œæ•¸æ“šã€‚å®ƒç„¡æ³•æä¾›è¶…å‡ºé€™äº›è³‡è¨Šç¯„åœçš„é€šç”¨ GMAT çŸ¥è­˜æˆ–å»ºè­°ã€‚

            **6. å¸¸è¦‹å•é¡Œ (FAQ)**

            - **Q: "é–‹å§‹åˆ†æ" æŒ‰éˆ•ç‚ºä»€éº¼ä¸èƒ½é»ï¼Ÿ**
                - A: è«‹ç¢ºä¿æ‚¨å·²ç¶“åœ¨ Q, V, DI ä¸‰å€‹åˆ†é éƒ½æˆåŠŸä¸Šå‚³æˆ–è²¼ä¸Šäº†æ•¸æ“šï¼Œä¸¦ä¸”é é¢ä¸Šæ–¹æ²’æœ‰é¡¯ç¤ºç´…è‰²çš„é©—è­‰éŒ¯èª¤è¨Šæ¯ã€‚å¿…é ˆä¸‰å€‹ç§‘ç›®éƒ½æœ‰æœ‰æ•ˆæ•¸æ“šæ‰èƒ½é–‹å§‹ã€‚
            - **Q: æˆ‘ä¸Šå‚³/è²¼ä¸Šçš„æ•¸æ“šå¥½åƒè®€å–ä¸å°æˆ–å ±éŒ¯ï¼Ÿ**
                - A: è«‹ä»”ç´°æª¢æŸ¥æ‚¨çš„æ•¸æ“šæ ¼å¼æ˜¯å¦ç¬¦åˆç¬¬ 2 ç¯€çš„è¦æ±‚ï¼Œç‰¹åˆ¥æ˜¯æ¬„ä½æ¨™é¡Œæ˜¯å¦å®Œå…¨ä¸€è‡´ã€æ•¸æ“šé¡å‹æ˜¯å¦æ­£ç¢ºï¼ˆæ™‚é–“æ˜¯æ•¸å­—ã€è¡¨ç¾æ˜¯'Correct'/'Incorrect'ç­‰ï¼‰ã€‚å¸¸è¦‹éŒ¯èª¤åŒ…å«ï¼šæ¬„ä½æ¨™é¡Œæ‰“éŒ¯å­—ã€å¤šäº†ç©ºæ ¼ã€CSV é€—è™Ÿä½¿ç”¨ä¸ç•¶ã€è²¼ä¸Šæ™‚æ ¼å¼æ··äº‚ç­‰ã€‚
            - **Q: å ±å‘Šè£¡çš„ã€Œé›£åº¦ã€æ˜¯æ€éº¼ä¾†çš„ï¼Ÿ**
                - A: é€™å€‹é›£åº¦æ˜¯å·¥å…·å…§éƒ¨é€é IRT æ¨¡æ“¬æ¼”ç®—æ³•ï¼Œæ ¹æ“šæ‚¨çš„ä½œç­”æ¨¡å¼ï¼ˆå°éŒ¯é †åºï¼‰ä¼°è¨ˆå‡ºä¾†çš„ç›¸å°é›£åº¦å€¼ï¼Œåƒ…ç”¨æ–¼æœ¬æ¬¡è¨ºæ–·åˆ†æï¼Œä¸¦éå®˜æ–¹å…¬ä½ˆçš„é¡Œç›®é›£åº¦ã€‚
            - **Q: AI åŠŸèƒ½ï¼ˆåŒ¯ç¸½å»ºè­°ã€å°è©±ï¼‰ç„¡æ³•ä½¿ç”¨ï¼Ÿ**
                - A: è«‹æª¢æŸ¥æ‚¨æ˜¯å¦åœ¨å´é‚Šæ¬„è¼¸å…¥äº†æœ‰æ•ˆçš„ OpenAI API Keyã€‚åŒæ™‚ï¼ŒAI åŠŸèƒ½åƒ…åœ¨ä¸»åˆ†ææˆåŠŸå®Œæˆå¾Œæ‰æœƒå•Ÿç”¨ã€‚å¦‚æœåˆ†æå¤±æ•—ï¼ŒAI åŠŸèƒ½ä¹Ÿç„¡æ³•ä½¿ç”¨ã€‚
            """)
        
        st.divider()
        
        # --- Data Input Section ---
        input_dfs, validation_errors, data_source_types = setup_input_tabs(preprocess_helpers)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é¡¯ç¤ºç¯„ä¾‹æ•¸æ“š
        if st.session_state.get('example_data_loaded', False) and st.session_state.get('example_data'):
            # æ³¨å…¥ç¯„ä¾‹æ•¸æ“šåˆ°input_dfs
            for subject in SUBJECTS:
                if subject in st.session_state['example_data']:
                    if input_dfs.get(subject) is None:  # åªæœ‰åœ¨å°šæœªè¼¸å…¥æ•¸æ“šæ™‚æ‰æ³¨å…¥
                        example_df = st.session_state['example_data'][subject].copy()
                        # æ·»åŠ å¿…è¦çš„åˆ—
                        example_df['is_manually_invalid'] = False
                        example_df['Subject'] = subject
                        
                        # é‡è¨­ç´¢å¼•ä»¥é¿å…æ½›åœ¨çš„ç´¢å¼•å•é¡Œ
                        example_df = example_df.reset_index(drop=True)
                        
                        # å°‡åŸå§‹æ•¸æ“šé‡å‘½åç‚ºæ¨™æº–åŒ–åˆ—å
                        rename_map = BASE_RENAME_MAP.copy()
                        if 'Question' in example_df.columns:
                            rename_map['Question'] = 'question_position'
                        if 'Response Time (Minutes)' in example_df.columns:
                            rename_map['Response Time (Minutes)'] = 'question_time'
                        if 'Performance' in example_df.columns:
                            rename_map['Performance'] = 'is_correct'
                            # è½‰æ›Performanceåˆ—ç‚ºis_correct
                            example_df['is_correct'] = example_df['Performance'].apply(
                                lambda x: x == 'Correct' if isinstance(x, str) else bool(x)
                            )
                        
                        example_df.rename(columns=rename_map, inplace=True)
                        
                        input_dfs[subject] = example_df
                        validation_errors[subject] = []
                        data_source_types[subject] = "ç¯„ä¾‹æ•¸æ“š"
            
            # æ¸…é™¤æ¨™èªŒï¼Œé¿å…é‡è¤‡åŠ è¼‰
            st.session_state['example_data_loaded'] = False
        
        # Store in session state
        st.session_state.input_dfs = input_dfs
        st.session_state.validation_errors = validation_errors
        st.session_state.data_source_types = data_source_types
        
        # Combine Input Data
        df_combined_input, loaded_subjects, valid_input_dfs = combine_input_data(input_dfs, SUBJECTS)
        
        # Check if any validation errors occurred across all tabs
        any_validation_errors = any(bool(warnings) for warnings in validation_errors.values())
        
        # Display Analysis Button with improved styling
        st.divider()
        st.subheader("3. é–‹å§‹åˆ†æ")
        button_clicked, button_disabled, button_message = display_analysis_button(
            df_combined_input, 
            any_validation_errors, 
            input_dfs,
            SUBJECTS
        )
        
        # --- Analysis Execution Block ---
        if button_clicked and not button_disabled:
            # This is a new analysis request
            reset_session_for_new_upload() # Clear previous *results* and *completion status*
            st.session_state.analysis_run = True # Mark that analysis should run *now*
                                               # This flag will persist for the current script run
                                               # to ensure results are displayed.
            st.session_state.diagnosis_complete = False # Ensure it starts as not complete

            if df_combined_input is not None:
                with st.spinner("æ­£åœ¨åŸ·è¡Œ IRT æ¨¡æ“¬èˆ‡è¨ºæ–·..."):
                    # --- Add to CSV ---
                    records_to_add = []
                    # Generate a unique student_id for this upload session if not available
                    # For simplicity, using a fixed student_id for now, or derive from session
                    student_id_for_batch = st.session_state.get("student_id_for_upload", f"student_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}")
                    st.session_state.student_id_for_upload = student_id_for_batch # Store for potential reuse in the session
                    
                    test_date_for_batch = datetime.date.today().isoformat()

                    # Calculate per-section totals first
                    section_stats = {}
                    if 'Subject' in df_combined_input.columns and 'question_time' in df_combined_input.columns:
                        for subject_name, group in df_combined_input.groupby('Subject'):
                            if subject_name in SUBJECTS: # Process only Q, V, DI
                                # Ensure question_time is numeric before summing
                                numeric_times = pd.to_numeric(group['question_time'], errors='coerce')
                                section_stats[subject_name] = {
                                    'total_questions': len(group),
                                    'total_time': numeric_times.sum()
                                }

                    for index, row in df_combined_input.iterrows():
                        record = {}
                        gmat_section = row.get("Subject")
                        
                        # Skip if not a main GMAT section (e.g. 'Total' if it exists in df_combined_input)
                        if gmat_section not in SUBJECTS:
                            continue
                            
                        record["student_id"] = student_id_for_batch
                        # Create a unique test_instance_id for each section within the batch
                        record["test_instance_id"] = f"{student_id_for_batch}_{gmat_section}_{test_date_for_batch.replace('-', '')}_upload"
                        record["gmat_section"] = gmat_section
                        record["test_date"] = test_date_for_batch
                        
                        question_pos = row.get("question_position", index + 1)
                        record["question_id"] = f"{gmat_section}_{question_pos}_{test_date_for_batch.replace('-', '')}"
                        record["question_position"] = int(question_pos) if pd.notnull(question_pos) else index + 1
                        # Ensure question_time is numeric before converting to float
                        question_time_val = row.get("question_time", 0.0)
                        if isinstance(question_time_val, str):
                            question_time_val = pd.to_numeric(question_time_val, errors='coerce')
                        record["question_time_minutes"] = float(question_time_val) if pd.notnull(question_time_val) else 0.0
                        
                        is_correct_val = row.get("is_correct")
                        if isinstance(is_correct_val, bool):
                            record["is_correct"] = 1 if is_correct_val else 0
                        elif isinstance(is_correct_val, str):
                            record["is_correct"] = 1 if is_correct_val.lower() == 'correct' else 0
                        else:
                            record["is_correct"] = 0 # Default if unknown format
                            
                        # question_difficulty might not be present in uploaded data, default to 0 or a placeholder
                        record["question_difficulty"] = float(row.get("question_difficulty", 0.0)) 
                        record["question_type"] = str(row.get("question_type", ""))
                        record["question_fundamental_skill"] = str(row.get("question_fundamental_skill", ""))
                        record["content_domain"] = str(row.get("content_domain", ""))
                        
                        if gmat_section in section_stats:
                            record["total_questions_in_section"] = int(section_stats[gmat_section]['total_questions'])
                            # Safely convert total_time to float, handle NaN values
                            total_time_val = section_stats[gmat_section]['total_time']
                            record["total_section_time_minutes"] = float(total_time_val) if pd.notnull(total_time_val) else 0.0
                        else:
                            record["total_questions_in_section"] = 0 # Should not happen if Subject is Q,V,DI
                            record["total_section_time_minutes"] = 0.0

                        record["max_allowed_section_time_minutes"] = 45.0 # Standard or from config
                        
                        # Ensure all GMAT_PERFORMANCE_HEADERS are present, even if with None or default values, except record_timestamp
                        for header in GMAT_PERFORMANCE_HEADERS:
                            if header not in record and header != "record_timestamp":
                                record[header] = None 
                        records_to_add.append(record)
                    
                    if records_to_add:
                        if add_gmat_performance_record(records_to_add):
                            # st.toast(f"å·²æˆåŠŸå°‡ {len(records_to_add)} ç­†è³‡æ–™é™„åŠ åˆ° gmat_performance_data.csv", icon="âœ…") # This line will be commented out
                            pass # Add pass if commenting out the toast makes the block empty
                        else:
                            st.toast("é™„åŠ è³‡æ–™åˆ° gmat_performance_data.csv æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚", icon="âš ï¸")
                    else:
                        st.toast("æ²’æœ‰å¯é™„åŠ åˆ° gmat_performance_data.csv çš„è³‡æ–™ã€‚", icon="â„¹ï¸")
                    # --- End Add to CSV ---
                    
                    # --- æ·»åŠ ä¸»è§€æ™‚é–“å£“åŠ›å ±å‘Šåˆ° CSV ---
                    subjective_reports_added = 0
                    
                    for subject in SUBJECTS:
                        subject_key = subject.lower()
                        time_pressure_key = f"{subject_key}_time_pressure"
                        
                        if time_pressure_key in st.session_state:
                            time_pressure_value = int(st.session_state[time_pressure_key])
                            test_instance_id = f"{student_id_for_batch}_{subject}_{test_date_for_batch.replace('-', '')}_upload"
                            
                            # å‰µå»ºä¸»è§€å ±å‘Šè¨˜éŒ„
                            subjective_report = {
                                "student_id": student_id_for_batch,
                                "test_instance_id": test_instance_id,
                                "gmat_section": subject,
                                "subjective_time_pressure": time_pressure_value,
                                "report_collection_timestamp": datetime.datetime.now().isoformat()
                            }
                            
                            # å°‡å ±å‘Šå¯«å…¥ CSV
                            if add_subjective_report_record(subjective_report):
                                subjective_reports_added += 1
                            else:
                                st.toast(f"æ·»åŠ  {subject} ç§‘ç›®çš„ä¸»è§€æ™‚é–“å£“åŠ›å ±å‘Šåˆ° CSV æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚", icon="âš ï¸")
                    
                    if subjective_reports_added > 0:
                        pass # æˆåŠŸæ·»åŠ å ±å‘Š
                    # --- æ·»åŠ ä¸»è§€æ™‚é–“å£“åŠ›å ±å‘Šåˆ° CSV çµæŸ ---

                    run_analysis(df_combined_input) # This will update diagnosis_complete and analysis_error
                
                if st.session_state.diagnosis_complete:
                    st.success("åˆ†æå®Œæˆï¼è«‹å‰å¾€é é¦–çš„ã€ŒçµæœæŸ¥çœ‹ã€åˆ†é æŸ¥çœ‹è¨ºæ–·çµæœã€‚")
            else:
                # If there's no data, then analysis didn't really "run" in a meaningful way.
                st.session_state.analysis_run = False 
                st.error("æ²’æœ‰åˆä½µçš„æ•¸æ“šå¯ä»¥åˆ†æï¼Œç„¡æ³•å•Ÿå‹•åˆ†æã€‚")
    
    with main_tabs[1]:  # çµæœæŸ¥çœ‹æ¨™ç±¤é 
        if st.session_state.get("diagnosis_complete", False):
            display_results()
        else:
            # é¡¯ç¤ºå°šæœªåˆ†æçš„æç¤º
            st.info("å°šæœªåŸ·è¡Œåˆ†æã€‚è«‹å…ˆåœ¨ã€Œæ•¸æ“šè¼¸å…¥èˆ‡åˆ†æã€æ¨™ç±¤ä¸­ä¸Šå‚³æ•¸æ“šä¸¦åŸ·è¡Œåˆ†æã€‚")
            st.markdown("""
            ### åˆ†ææµç¨‹èªªæ˜
            
            1. åœ¨ã€Œæ•¸æ“šè¼¸å…¥èˆ‡åˆ†æã€æ¨™ç±¤ä¸­ä¸Šå‚³ä¸‰å€‹ç§‘ç›®çš„æ•¸æ“š
            2. ç¢ºä¿æ•¸æ“šæ ¼å¼æ­£ç¢ºä¸¦é€šéé©—è­‰
            3. é»æ“Šã€Œé–‹å§‹åˆ†æã€æŒ‰éˆ•
            4. åˆ†æå®Œæˆå¾Œï¼Œçµæœå°‡é¡¯ç¤ºåœ¨æ­¤é é¢
            """)
            
    # --- Sidebar Settings ---
    st.sidebar.subheader("åˆ†æè¨­å®š")
    
    # æ·»åŠ ç¯„ä¾‹æ•¸æ“šå°å…¥åŠŸèƒ½
    with st.sidebar.expander("ğŸ“Š ç¯„ä¾‹æ•¸æ“š", expanded=True):
        st.markdown("### ç¯„ä¾‹æ•¸æ“šå°å…¥")
        st.markdown("é»æ“Šä¸‹æ–¹æŒ‰éˆ•å°å…¥ç¯„ä¾‹åšé¡Œæ•¸æ“šï¼Œæ–¹ä¾¿é«”é©—ç³»çµ±åŠŸèƒ½")
        
        st.button("ä¸€éµå°å…¥ç¯„ä¾‹æ•¸æ“š", 
                  key="load_sample_data_pasted", 
                  use_container_width=True,
                  on_click=load_sample_data_callback) # Use on_click callback

        if st.session_state.get('sample_data_pasted_success', False):
            st.success("ç¯„ä¾‹æ•¸æ“šå·²æˆåŠŸå¡«å…¥å„ç§‘ç›®çš„æ–‡æœ¬æ¡†ï¼è«‹æª¢æŸ¥ã€Œæ•¸æ“šè¼¸å…¥èˆ‡åˆ†æã€é é¢ã€‚")
            st.session_state.sample_data_pasted_success = False # Reset flag
            
    # OpenAIè¨­å®šå€å¡Šï¼ˆç§»åˆ°ä¸Šæ–¹æ›´æ˜é¡¯çš„ä½ç½®ï¼‰
    with st.sidebar.expander("ğŸ¤– AIåŠŸèƒ½è¨­å®š", expanded=False):
        master_key_input = st.text_input(
            "è¼¸å…¥ç®¡ç†å“¡é‡‘é‘°å•Ÿç”¨ AI å•ç­”åŠŸèƒ½ï¼š",
            type="password",
            key="master_key_input",
            value=st.session_state.get('master_key', ''),
            help="è¼¸å…¥æœ‰æ•ˆç®¡ç†é‡‘é‘°ä¸¦æˆåŠŸå®Œæˆåˆ†æå¾Œï¼Œä¸‹æ–¹å°‡å‡ºç¾ AI å°è©±æ¡†ã€‚ç®¡ç†é‡‘é‘°è«‹å‘ç³»çµ±ç®¡ç†å“¡ç´¢å–ã€‚"
        )

        # Update session state when input changes
        if master_key_input:
            st.session_state.master_key = master_key_input
            # ä½¿ç”¨æ–°çš„æ–¹æ³•åŸºæ–¼master keyåˆå§‹åŒ–OpenAIå®¢æˆ¶ç«¯
            from gmat_diagnosis_app.services.openai_service import initialize_openai_client_with_master_key
            if initialize_openai_client_with_master_key(master_key_input):
                st.session_state.show_chat = True
                st.session_state.chat_history = []
                st.success("ç®¡ç†é‡‘é‘°é©—è­‰æˆåŠŸï¼ŒAIåŠŸèƒ½å·²å•Ÿç”¨ï¼")
            else:
                st.session_state.show_chat = False
                st.session_state.chat_history = []
                st.error("ç®¡ç†é‡‘é‘°é©—è­‰å¤±æ•—ï¼Œç„¡æ³•å•Ÿç”¨AIåŠŸèƒ½ã€‚")
        else:
            st.session_state.master_key = None
            st.session_state.show_chat = False
            st.session_state.chat_history = []

    # --- IRT Simulation Settings ---
    with st.sidebar.expander("ğŸ“Š IRTæ¨¡æ“¬è¨­å®š", expanded=False):
        st.session_state.initial_theta_q = st.number_input(
            "Q ç§‘ç›®åˆå§‹ Theta ä¼°è¨ˆ", 
            value=st.session_state.initial_theta_q, 
            step=0.1,
            key="theta_q_input"
        )
        st.session_state.initial_theta_v = st.number_input(
            "V ç§‘ç›®åˆå§‹ Theta ä¼°è¨ˆ", 
            value=st.session_state.initial_theta_v, 
            step=0.1,
            key="theta_v_input"
        )
        st.session_state.initial_theta_di = st.number_input(
            "DI ç§‘ç›®åˆå§‹ Theta ä¼°è¨ˆ", 
            value=st.session_state.initial_theta_di, 
            step=0.1,
            key="theta_di_input"
        )

    # --- Manual IRT Adjustment Inputs in Sidebar ---
    with st.sidebar.expander("ğŸ”§ æ‰‹å‹•èª¿æ•´é¡Œç›®", expanded=False):
        st.markdown("#### æ‰‹å‹•èª¿æ•´é¡Œç›®æ­£ç¢ºæ€§")
        st.markdown("ï¼ˆåƒ…å½±éŸ¿IRTæ¨¡æ“¬ï¼‰")
        
        # ä½¿ç”¨æ¨™ç±¤é ç¯€çœç©ºé–“
        q_tab, v_tab, di_tab = st.tabs(["Q", "V", "DI"])
        
        with q_tab:
            st.session_state.q_incorrect_to_correct_qns = st.text_input(
                "ç”±éŒ¯æ”¹å°é¡Œè™Ÿ", 
                value=st.session_state.q_incorrect_to_correct_qns,
                placeholder="ä¾‹: 1,5,10",
                key="q_i_to_c_input"
            )
            st.session_state.q_correct_to_incorrect_qns = st.text_input(
                "ç”±å°æ”¹éŒ¯é¡Œè™Ÿ", 
                value=st.session_state.q_correct_to_incorrect_qns,
                placeholder="ä¾‹: 2,7,12",
                key="q_c_to_i_input"
            )
        
        with v_tab:
            st.session_state.v_incorrect_to_correct_qns = st.text_input(
                "ç”±éŒ¯æ”¹å°é¡Œè™Ÿ", 
                value=st.session_state.v_incorrect_to_correct_qns,
                placeholder="ä¾‹: 1,5,10",
                key="v_i_to_c_input"
            )
            st.session_state.v_correct_to_incorrect_qns = st.text_input(
                "ç”±å°æ”¹éŒ¯é¡Œè™Ÿ", 
                value=st.session_state.v_correct_to_incorrect_qns,
                placeholder="ä¾‹: 2,7,12",
                key="v_c_to_i_input"
            )
        
        with di_tab:
            st.session_state.di_incorrect_to_correct_qns = st.text_input(
                "ç”±éŒ¯æ”¹å°é¡Œè™Ÿ", 
                value=st.session_state.di_incorrect_to_correct_qns,
                placeholder="ä¾‹: 1,5,10",
                key="di_i_to_c_input"
            )
            st.session_state.di_correct_to_incorrect_qns = st.text_input(
                "ç”±å°æ”¹éŒ¯é¡Œè™Ÿ", 
                value=st.session_state.di_correct_to_incorrect_qns,
                placeholder="ä¾‹: 2,7,12",
                key="di_c_to_i_input"
            )
    
    # é å°¾ä¿¡æ¯
    st.markdown("---")
    st.caption("æœ‰å•é¡Œæˆ–å»ºè­°ï¼Ÿè«‹å‰å¾€ [GitHub Issues](https://github.com/danyuchn/GMAT-score-report-analysis/issues) æäº¤åé¥‹")

if __name__ == "__main__":
    main() 