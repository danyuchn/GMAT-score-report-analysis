# -*- coding: utf-8 -*- # Ensure UTF-8 encoding for comments/strings
import streamlit as st

# Call set_page_config as the first Streamlit command
st.set_page_config(
    page_title="GMAT ÊàêÁ∏æË®∫Êñ∑Âπ≥Âè∞",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

from dotenv import load_dotenv
load_dotenv()

import sys
import os
import io
import pandas as pd
import numpy as np
import logging
import openai
import plotly.graph_objects as go
import datetime

# --- Project Path Setup ---
try:
    app_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(app_dir)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
except NameError:
    # Handle cases where __file__ is not defined (e.g., interactive environments)
    st.warning("Could not automatically determine project root. Assuming modules are available.", icon="‚ö†Ô∏è")
    project_root = os.getcwd()  # Fallback

# --- Module Imports ---
try:
    # Import custom modules for core logic
    from gmat_diagnosis_app import preprocess_helpers # Ensure the module itself is imported for setup_input_tabs
    # from gmat_diagnosis_app import irt_module as irt # Moved to analysis_orchestrator
    # from gmat_diagnosis_app.irt import probability_correct, item_information, estimate_theta, initialize_question_bank, simulate_cat_exam
    # from gmat_diagnosis_app.diagnostics.v_diagnostic import run_v_diagnosis_processed # Moved
    # from gmat_diagnosis_app.diagnostics.di_diagnostic import run_di_diagnosis_processed # Moved
    # from gmat_diagnosis_app.diagnostics.q_diagnostic import diagnose_q # Moved
    
    # Import our modularized components
    from gmat_diagnosis_app.constants.config import (
        SUBJECTS, # Retained: Used in main for iterating tabs and processing
        # MAX_FILE_SIZE_MB, MAX_FILE_SIZE_BYTES, # Removed: Likely used within setup_input_tabs
        # BANK_SIZE, RANDOM_SEED, SUBJECT_SIM_PARAMS, FINAL_DIAGNOSIS_INPUT_COLS, # Removed: Likely used in analysis_orchestrator or deeper
        BASE_RENAME_MAP # Retained: Used in main for sample data processing
        # REQUIRED_ORIGINAL_COLS, EXCEL_COLUMN_MAP # Removed: Likely used within setup_input_tabs or preprocess_helpers
    )
    # from gmat_diagnosis_app.constants.thresholds import THRESHOLDS # Removed: Likely used in analysis_orchestrator or deeper
    # from gmat_diagnosis_app.utils.validation import validate_dataframe
    # from gmat_diagnosis_app.utils.data_processing import process_subject_tab
    # from gmat_diagnosis_app.utils.styling import apply_styles
    # from gmat_diagnosis_app.utils.excel_utils import to_excel # Removed
    from gmat_diagnosis_app.services.openai_service import ( # Retained: get_chat_context, get_openai_response might be used by a chat interface if it were called
        # summarize_report_with_openai, generate_ai_consolidated_report, # Removed: Assumed handled by orchestrator/display
        get_chat_context, get_openai_response # Retained cautiously, though display_chat_interface is not called
    )
    # from gmat_diagnosis_app.services.plotting_service import create_theta_plot
    from gmat_diagnosis_app.ui.results_display import display_results # Removed display_subject_results
    # from gmat_diagnosis_app.ui.chat_interface import display_chat_interface # Removed: Not called
    from gmat_diagnosis_app.ui.input_tabs import setup_input_tabs, combine_input_data, display_analysis_button
    from gmat_diagnosis_app.session_manager import init_session_state, reset_session_for_new_upload, ensure_chat_history_persistence
    from gmat_diagnosis_app.analysis_orchestrator import run_analysis # Added import
    from gmat_diagnosis_app.services.csv_data_service import add_gmat_performance_record, GMAT_PERFORMANCE_HEADERS, add_subjective_report_record # Added for CSV export and new function
    
    # Import the new analysis helpers - These are likely used by analysis_orchestrator, not directly here.
    # from gmat_diagnosis_app.analysis_helpers.time_pressure_analyzer import calculate_time_pressure, calculate_and_apply_invalid_logic # Removed
    # from gmat_diagnosis_app.analysis_helpers.simulation_manager import run_simulation, prepare_dataframes_for_diagnosis # Removed
    # from gmat_diagnosis_app.analysis_helpers.diagnosis_manager import run_diagnosis, update_session_state_after_analysis # Removed
    
except ImportError as e:
    st.error(f"Â∞éÂÖ•Ê®°ÁµÑÊôÇÂá∫ÈåØ: {e}. Ë´ãÁ¢∫‰øùÁí∞Â¢ÉË®≠ÂÆöÊ≠£Á¢∫Ôºå‰∏î gmat_diagnosis_app Âú® Python Ë∑ØÂæë‰∏≠„ÄÇ")
    st.stop()

# --- Initialize Column Display Configuration ---
# COLUMN_DISPLAY_CONFIG moved to ui/results_display.py

# --- Session State Functions ---
# init_session_state and reset_session_for_new_upload moved to session_manager.py

# --- Analysis Functions ---
# run_analysis moved to analysis_orchestrator.py

# --- Display Results Function ---
# display_results moved to ui.results_display.py

# Callback function for loading sample data
def load_sample_data_callback():
    """Sets session state for sample data to be pasted into text areas."""
    sample_q_data = """Question	Response Time (Minutes)	Performance	Content Domain	Question Type	Fundamental Skills
1	2.3	Correct	Algebra	REAL	Equal/Unequal/ALG
2	4.8	Correct	Algebra	REAL	Rates/Ratio/Percent
3	1.3	Correct	Arithmetic	REAL	Equal/Unequal/ALG
4	2.2	Incorrect	Arithmetic	REAL	Value/Order/Factors
5	0.8	Correct	Arithmetic	REAL	Rates/Ratio/Percent
6	3.5	Correct	Algebra	REAL	Rates/Ratio/Percent
7	1.5	Correct	Algebra	REAL	Equal/Unequal/ALG
8	1.5	Correct	Arithmetic	REAL	Rates/Ratio/Percent
9	1.3	Correct	Arithmetic	REAL	Counting/Sets/Series/Prob/Stats
10	5.4	Correct	Arithmetic	REAL	Counting/Sets/Series/Prob/Stats
11	2.6	Incorrect	Algebra	PURE	Equal/Unequal/ALG
12	4.3	Correct	Arithmetic	PURE	Rates/Ratio/Percent
13	1.6	Incorrect	Arithmetic	PURE	Counting/Sets/Series/Prob/Stats
14	0.9	Correct	Arithmetic	REAL	Counting/Sets/Series/Prob/Stats
15	0.7	Correct	Algebra	PURE	Value/Order/Factors
16	4.6	Correct	Algebra	PURE	Value/Order/Factors
17	2.1	Correct	Algebra	PURE	Counting/Sets/Series/Prob/Stats
18	0.7	Correct	Arithmetic	PURE	Equal/Unequal/ALG
19	0.7	Correct	Arithmetic	PURE	Rates/Ratio/Percent
20	0.8	Incorrect	Arithmetic	PURE	Value/Order/Factors
21	0.9	Correct	Arithmetic	PURE	Value/Order/Factors"""

    sample_v_data = """Question	Response Time (Minutes)	Performance	Content Domain	Question Type	Fundamental Skills
1	1.5	Correct	N/A	Critical Reasoning	Plan/Construct
2	3.6	Correct	N/A	Critical Reasoning	Plan/Construct
3	3	Correct	N/A	Reading Comprehension	Identify Stated Idea
4	1	Incorrect	N/A	Reading Comprehension	Identify Inferred Idea
5	3.7	Incorrect	N/A	Reading Comprehension	Identify Inferred Idea
6	1.7	Incorrect	N/A	Critical Reasoning	Analysis/Critique
7	2.7	Correct	N/A	Reading Comprehension	Identify Inferred Idea
8	1	Correct	N/A	Reading Comprehension	Identify Stated Idea
9	1.6	Correct	N/A	Reading Comprehension	Identify Inferred Idea
10	2.2	Correct	N/A	Critical Reasoning	Plan/Construct
11	4.4	Correct	N/A	Reading Comprehension	Identify Inferred Idea
12	0.6	Correct	N/A	Reading Comprehension	Identify Stated Idea
13	2.3	Correct	N/A	Reading Comprehension	Identify Inferred Idea
14	0.6	Correct	N/A	Reading Comprehension	Identify Stated Idea
15	2.4	Incorrect	N/A	Critical Reasoning	Analysis/Critique
16	2.3	Incorrect	N/A	Critical Reasoning	Analysis/Critique
17	2.8	Incorrect	N/A	Critical Reasoning	Plan/Construct
18	1.3	Correct	N/A	Critical Reasoning	Analysis/Critique
19	0.7	Correct	N/A	Critical Reasoning	Analysis/Critique
20	1.9	Incorrect	N/A	Critical Reasoning	Analysis/Critique
21	1.4	Incorrect	N/A	Critical Reasoning	Analysis/Critique
22	1	Correct	N/A	Critical Reasoning	Plan/Construct
23	1.2	Incorrect	N/A	Critical Reasoning	Plan/Construct"""

    sample_di_data = """Question	Response Time (Minutes)	Performance	Content Domain	Question Type	Fundamental Skills
1	1.5	Correct	Math Related	Data Sufficiency	N/A
2	1.8	Correct	Math Related	Data Sufficiency	N/A
3	3.1	Correct	Non-Math Related	Two-part analysis	N/A
4	4.2	Correct	Math Related	Multi-source reasoning	N/A
5	1.9	Incorrect	Non-Math Related	Multi-source reasoning	N/A
6	1	Incorrect	Math Related	Multi-source reasoning	N/A
7	3.7	Incorrect	Non-Math Related	Data Sufficiency	N/A
8	2.5	Incorrect	Non-Math Related	Graph and Table	N/A
9	5.9	Correct	Non-Math Related	Two-part analysis	N/A
10	2.7	Incorrect	Math Related	Graph and Table	N/A
11	2.1	Incorrect	Math Related	Data Sufficiency	N/A
12	1.7	Incorrect	Math Related	Data Sufficiency	N/A
13	2.8	Correct	Non-Math Related	Graph and Table	N/A
14	1.5	Incorrect	Math Related	Data Sufficiency	N/A
15	2	Incorrect	Non-Math Related	Graph and Table	N/A
16	1.2	Incorrect	Non-Math Related	Data Sufficiency	N/A
17	0.4	Incorrect	Math Related	Two-part analysis	N/A
18	3.5	Incorrect	Math Related	Graph and Table	N/A
19	0.1	Incorrect	Math Related	Two-part analysis	N/A
20	1.2	Incorrect	Math Related	Graph and Table	N/A"""

    st.session_state.q_paster = sample_q_data
    st.session_state.v_paster = sample_v_data
    st.session_state.di_paster = sample_di_data
    
    if 'example_data_loaded' in st.session_state:
        del st.session_state['example_data_loaded']
    if 'example_data' in st.session_state:
        del st.session_state['example_data']
    
    st.session_state.sample_data_pasted_success = True

# --- Main Application ---
def main():
    """Main application entry point"""
    # Ë®≠ÁΩÆÈ†ÅÈù¢ÈÖçÁΩÆ
    # st.set_page_config( # This block will be removed
    #     page_title="GMAT ÊàêÁ∏æË®∫Êñ∑Âπ≥Âè∞",
    #     page_icon="üìä",
    #     layout="wide",
    #     initial_sidebar_state="expanded"
    # )
    
    # Initialize session state
    init_session_state()
    
    # È°çÂ§ñÁ¢∫‰øùËÅäÂ§©Ê≠∑Âè≤ÊåÅ‰πÖÂåñ
    ensure_chat_history_persistence()

    # Initialize the success message flag for sample data pasting if it doesn't exist
    if 'sample_data_pasted_success' not in st.session_state:
        st.session_state.sample_data_pasted_success = False
    
    # È†ÅÈù¢Ê®ôÈ°åËàáÁ∞°‰ªãÂçÄ
    col1, col2 = st.columns([5, 1])
    with col1:
        st.title('üìä GMAT ÊàêÁ∏æË®∫Êñ∑Âπ≥Âè∞ by Dustin')
        st.markdown('ÈÄèÈÅéÊï∏ÊìöÂàÜÊûêÊ∑±ÂÖ•‰∫ÜËß£ÊÇ®ÁöÑGMATË°®ÁèæÔºåÊâæÂá∫ÈóúÈçµÊîπÈÄ≤Èªû')
    
    # Âª∫Á´ã‰∏ªË¶ÅÂ∞éËà™
    main_tabs = st.tabs(["üì• Êï∏ÊìöËº∏ÂÖ•ËàáÂàÜÊûê", "üìà ÁµêÊûúÊü•Áúã"])
    
    with main_tabs[0]:  # Êï∏ÊìöËº∏ÂÖ•ËàáÂàÜÊûêÊ®ôÁ±§È†Å
        # Á∞°Áü≠‰ΩøÁî®ÊåáÂºïÔºàÊ†∏ÂøÉÊ≠•È©üÔºâ
        with st.expander("Âø´ÈÄü‰ΩøÁî®ÊåáÂçó üëâ", expanded=False):
            st.markdown("""
            1. **Ê∫ñÂÇôÊï∏Êìö**: Á¢∫‰øùÊúâQuantitative„ÄÅVerbalÂíåData Insights‰∏âÁßëÁõÆÁöÑÊï∏Êìö
            2. **Ëº∏ÂÖ•Êï∏Êìö**: Âú®‰∏ãÊñπÂõõÂÄãÊ®ôÁ±§‰∏≠ÂàÜÂà•‰∏äÂÇ≥ÊàñË≤º‰∏äÊï∏ÊìöÔºå‰ª•ÂèäÂú®TotalÈ†ÅÁ±§‰∏≠Ë™øÊï¥ÂàÜÊï∏
            3. **Ê™¢Êü•È†êË¶Ω**: Á¢∫Ë™çÊï∏ÊìöÊ≠£Á¢∫‰∏¶Ê®ôË®òÁÑ°ÊïàÈ°åÁõÆÔºàÊôÇÈñìÂ£ìÂäõ‰∏ãÂÄâ‰øÉÂÅöÈ°åÊàñÁåúÈ°åÔºâ
            4. **Ë®≠ÂÆöÂèÉÊï∏**: Âú®ÂÅ¥ÈÇäÊ¨ÑË™øÊï¥ÂàÜÊûêÂèÉÊï∏ÔºàÂèØÈÅ∏Ôºâ
            5. **ÈñãÂßãÂàÜÊûê**: ÈªûÊìäÁ¥ÖËâ≤ÂàÜÊûêÊåâÈàï
            """)
            
        # --- Disclaimer & Tutorial Links ---
        disclaimer_warning = st.expander("ÈáçË¶ÅËÅ≤ÊòéËàá‰ΩøÁî®Ê¢ùÊ¨æÔºà‰ΩøÁî®Âç≥‰ª£Ë°®ÂêåÊÑèÔºâ", expanded=False)
        with disclaimer_warning:
            st.markdown("""
            ### Ë´ã‰ªîÁ¥∞Èñ±ËÆÄ‰ª•‰∏ãË™™ÊòéÔºö

            Êú¨ÂàÜÊûêÂ∑•ÂÖ∑Êèê‰æõÁöÑÊòØÂü∫ÊñºÊÇ®Ëº∏ÂÖ•Êï∏ÊìöÁöÑÁ¥îÈáèÂåñÂàÜÊûê„ÄÇÂàÜÊûêÁöÑÊ∫ñÁ¢∫ÊÄßÈ´òÂ∫¶‰æùË≥¥ÊÇ®ÊâÄËº∏ÂÖ•Êï∏ÊìöÁöÑÂÆåÊï¥ÊÄßËàáÊ≠£Á¢∫ÊÄß„ÄÇÊú¨Â∑•ÂÖ∑Êé°Áî®È†êË®≠ÂèÉÊï∏ËàáÊ®ôÊ∫ñÂåñË®∫Êñ∑ÈÇèËºØÈÄ≤Ë°åÈÅãÁÆóÔºåÂÖ∂‰∏≠Ôºö

            1.  **È°åÁõÆÈõ£Â∫¶ÂÄº**ÔºöÂ†±Âëä‰∏≠ÊâÄ‰ΩøÁî®ÁöÑÈ°åÁõÆÈõ£Â∫¶Êï∏ÊìöÊòØÂü∫ÊñºÂÖßÈÉ®Ê®°ÂûãÁöÑ IRT Ê®°Êì¨‰º∞Ë®àÂÄºÔºåÂÖ∂ÁõÆÁöÑÊòØÁÇ∫‰∫ÜÂú®Êú¨ÂàÜÊûêÊ°ÜÊû∂ÂÖßÈÄ≤Ë°åÁõ∏Â∞çÊØîËºÉËàáË®∫Êñ∑Ôºå‰∏¶‰∏ç‰ª£Ë°® GMAT ÂÆòÊñπËÄÉË©¶ÁöÑÁúüÂØ¶È°åÁõÆÈõ£Â∫¶„ÄÇ
            2.  **Êï∏ÊìöÁØ©ÈÅ∏**ÔºöÂàÜÊûêÈÅéÁ®ãÂèØËÉΩÂ∑≤Ê†πÊìöË¶èÂâáÔºà‰æãÂ¶ÇÔºö‰ΩúÁ≠îÊôÇÈñìÁï∞Â∏∏Á≠âÔºâËá™ÂãïÁØ©ÈÅ∏ÈÉ®ÂàÜË¢´Âà§ÂÆöÁÇ∫ÁÑ°ÊïàÁöÑÊï∏ÊìöÈªû„ÄÇ

            Âõ†Ê≠§ÔºåÊú¨Â†±ÂëäÁî¢Âá∫ÁöÑÊâÄÊúâË®∫Êñ∑Ê®ôÁ±§„ÄÅÂàÜÊûêÊ¥ûË¶ãËàáÂª∫Ë≠∞Ë°åÂãïÔºåÂùáÁÇ∫ÈáèÂåñÊï∏ÊìöÂàÜÊûêÁöÑÂàùÊ≠•ÁµêÊûúÔºåÂÉÖ‰æõÂèÉËÄÉÔºå‰∏çËÉΩÂÆåÂÖ®Âèñ‰ª£ÂØ¶ÈöõÊÉÖÊ≥ÅÁöÑÂà§Êñ∑„ÄÇ

            ÊàëÂÄëÂº∑ÁÉàÂª∫Ë≠∞ÊÇ®Â∞áÊ≠§ÈáèÂåñÂ†±Âëä‰ΩúÁÇ∫ËºîÂä©Â∑•ÂÖ∑Ôºå‰∏¶ËàáÁ∂ìÈ©óË±êÂØåÁöÑ GMAT ÊïôÂ∏´ÊàñÂ∞àÊ•≠È°ßÂïè‰∏ÄÂêåÊ™¢Ë¶ñ„ÄÇÈÄèÈÅéÂ∞àÊ•≠‰∫∫Â£´ÈÄ≤‰∏ÄÊ≠•ÁöÑ„ÄåË≥™ÂåñÂàÜÊûê„ÄçÔºà‰æãÂ¶ÇÔºöÊé¢Ë®éÂÖ∑È´îÈåØË™§ÊÄùË∑Ø„ÄÅËß£È°åÁøíÊÖ£„ÄÅÂøÉÊÖãÂΩ±ÈüøÁ≠âÔºâÔºåÊâçËÉΩÊõ¥Ê∑±ÂÖ•„ÄÅÊ∫ñÁ¢∫Âú∞Ëß£ËÆÄÊÇ®ÁöÑË°®ÁèæÔºåÊâæÂá∫Ê†πÊú¨ÂïèÈ°åÔºå‰∏¶Âà∂ÂÆöÊúÄÊúâÊïàÁöÑÂÄã‰∫∫ÂåñÂ≠∏ÁøíËàáÂÇôËÄÉÁ≠ñÁï•„ÄÇ

            ---

            ### Êï∏Êìö‰ΩøÁî®ËàáÂèçÈ•ãÔºö

            *   **Êï∏ÊìöÊî∂ÈõÜÂêåÊÑè**ÔºöÁï∂ÊÇ®‰ΩøÁî®Êú¨Â∑•ÂÖ∑‰∏¶‰∏äÂÇ≥ÊÇ®ÁöÑ GMAT ÊàêÁ∏æÂñÆÊï∏ÊìöÊôÇÔºåÂç≥Ë°®Á§∫ÊÇ®ÁêÜËß£‰∏¶ÂêåÊÑèÊéàÊ¨äÈñãÁôºËÄÖÔºàÊàëÔºâÊî∂ÈõÜÈÄô‰∫õÊï∏ÊìöÔºåÁî®ÊñºÂæåÁ∫åÊ®°ÂûãÂÑ™Âåñ„ÄÅÂ≠∏Ë°ìÁ†îÁ©∂ÊàñÂÖ∂‰ªñÁõ∏ÈóúÂàÜÊûêÁõÆÁöÑ„ÄÇ
            *   **ÂéªË≠òÂà•ÂåñË≤¨‰ªª**ÔºöÁÇ∫‰øùË≠∑ÊÇ®ÁöÑÂÄã‰∫∫Èö±ÁßÅÔºåË´ãÂãôÂøÖÂú®‰∏äÂÇ≥ÂâçÔºå‰ªîÁ¥∞Ê™¢Êü•‰∏¶ÊâãÂãïÂéªÈô§ÊÇ®ÊàêÁ∏æÂñÆÊï∏Êìö‰∏≠ÁöÑÊâÄÊúâÂÄã‰∫∫Ë∫´‰ªΩË≠òÂà•Ë≥áË®äÔºà‰æãÂ¶ÇÔºöÂßìÂêç„ÄÅËÄÉÁîü ID„ÄÅËÄÉË©¶‰∏≠ÂøÉ„ÄÅÈõªÂ≠êÈÉµ‰ª∂Âú∞ÂùÄÁ≠âÔºâ„ÄÇÁ¢∫‰øùÊÇ®‰∏äÂÇ≥ÁöÑÊï∏ÊìöÂ∑≤ÁÑ°Ê≥ïËøΩÊ∫ØÂà∞ÊÇ®ÂÄã‰∫∫„ÄÇË´ãË¨πÊÖéÊìç‰Ωú„ÄÇ
            *   **ÂïèÈ°åÂèçÈ•ã**ÔºöÊ≠°ËøéÊÇ®ÈÄèÈÅé GitHub Issues Êèê‰∫§‰ΩøÁî®ÂèçÈ•ã„ÄÅÁôºÁèæÁöÑÂïèÈ°åÊàñÂª∫Ë≠∞„ÄÇË´ãËá≥Ôºöhttps://github.com/danyuchn/GMAT-score-report-analysis/issues
            """)
            
        tutorial_help = st.expander("ÂÆåÊï¥‰ΩøÁî®Ë™™Êòé", expanded=False)
        with tutorial_help:
            st.markdown("""
            **GMAT ÊàêÁ∏æË®∫Êñ∑Âπ≥Âè∞‰ΩøÁî®Ë™™Êòé**

            **1. Ê≠°ËøéÔºÅÊú¨Â∑•ÂÖ∑ËÉΩÂÅö‰ªÄÈ∫ºÔºü**

            Ê≠°Ëøé‰ΩøÁî® GMAT ÊàêÁ∏æË®∫Êñ∑Âπ≥Âè∞ÔºÅÈÄôÂÄãÂ∑•ÂÖ∑Êó®Âú®Âπ´Âä© GMAT ËÄÉÁîüÂíåÊïôÂ≠∏ËÄÖÔºö

            - **Ë∂ÖË∂äÂñÆÁ¥îÂàÜÊï∏Ôºö** ‰∏çÂè™ÁúãÂ∞çÈåØÔºåÊõ¥Ê∑±ÂÖ•ÂàÜÊûêÊÇ®Âú® GMAT ÂêÑÁßëÁõÆ (Quantitative, Verbal, Data Insights) Ë°®ÁèæËÉåÂæåÁöÑÊ†πÊú¨ÂéüÂõ†„ÄÇ
            - **ÊâæÂá∫Âº±ÈªûÊ®°ÂºèÔºö** Ë≠òÂà•ÊÇ®Âú®ÁâπÂÆöÈ°åÂûã„ÄÅÁü•Ë≠òÈªûÊàñÊäÄËÉΩ‰∏äÁöÑÈåØË™§Ê®°Âºè„ÄÅÊôÇÈñìÁÆ°ÁêÜÂïèÈ°åÊàñ‰∏çÁ©©ÂÆöÁöÑÊ¶ÇÂøµÊéåÊè°Ôºà‰æãÂ¶Ç Special Focus Errors, SFEÔºâ„ÄÇ
            - **Áç≤ÂæóÂÄã‰∫∫ÂåñÂª∫Ë≠∞Ôºö** Ê†πÊìöË®∫Êñ∑ÁµêÊûúÔºåÊèê‰æõÂÖ∑È´îÁöÑÁ∑¥ÁøíÊñπÂêëÔºåÂåÖÊã¨Âª∫Ë≠∞ÁöÑÁ∑¥ÁøíÈõ£Â∫¶ÂíåËµ∑ÂßãÊôÇÈñìÈôêÂà∂„ÄÇ
            - **ÊèêÂçáÂÇôËÄÉÊïàÁéáÔºö** ËÆìÊÇ®ÁöÑÁ∑¥ÁøíÊõ¥ÊúâÈáùÂ∞çÊÄßÔºåÊääÊôÇÈñìËä±Âú®ÊúÄÈúÄË¶ÅÂä†Âº∑ÁöÑÂú∞Êñπ„ÄÇ

            **2. ÈñãÂßã‰πãÂâçÔºöÊ∫ñÂÇôÊÇ®ÁöÑÊàêÁ∏æÂñÆÊï∏Êìö**

            **„ÄåÊï∏ÊìöÂìÅË≥™ÊòØË®∫Êñ∑Ê∫ñÁ¢∫ÁöÑÂü∫Áü≥ÔºÅ„Äç** Ë´ãÂãôÂøÖÊ∫ñÂÇôÁ¨¶ÂêàÊ†ºÂºèË¶ÅÊ±ÇÁöÑÊï∏Êìö„ÄÇ

            - **Êï∏Êìö‰æÜÊ∫êÔºö** ÊÇ®ÂèØ‰ª•‰ΩøÁî®ÂÆòÊñπÂ¢ûÂº∑ÁâàÊàêÁ∏æÂñÆ (ESR)„ÄÅÂÆòÊñπÁ∑¥Áøí (Official Practice Exams)„ÄÅÁ¨¨‰∏âÊñπÊ®°ËÄÉÂπ≥Âè∞ÔºåÊàñÊÇ®Ëá™Â∑±Ë®òÈåÑÁöÑÁ∑¥ÁøíÊï∏ÊìöÔºåÂè™Ë¶ÅÁ¨¶Âêà‰ª•‰∏ãÊ†ºÂºèÂç≥ÂèØ„ÄÇ
            - **Ê†ºÂºèË¶ÅÊ±ÇÔºö**
                - ÈúÄË¶Å**ÂàÜÂà•**Ê∫ñÂÇô Quantitative (Q), Verbal (V), Data Insights (DI) ‰∏âÂÄãÁßëÁõÆÁöÑÊï∏Êìö„ÄÇ
                - ÊÇ®ÂèØ‰ª•‰∏äÂÇ≥ **CSV Ê™îÊ°à**ÔºàÊ™îÊ°àÂ§ßÂ∞èÈôêÂà∂ 1MBÔºâÊàñÁõ¥Êé•Âæû **Excel/Ë°®Ê†º** Ë§áË£ΩÊï∏Êìö‰∏¶Ë≤º‰∏ä„ÄÇ
            - **ÂøÖË¶ÅÊ¨Ñ‰ΩçÔºàÊ¨Ñ‰ΩçÊ®ôÈ°åÈ†àÂÆåÂÖ®Á¨¶ÂêàÔºåÂ§ßÂ∞èÂØ´/Á©∫Ê†ºÊïèÊÑüÔºâÔºö**
                - **ÈÄöÁî®Ê¨Ñ‰Ωç:**
                    - `Question`: È°åËôü (ÂøÖÈ†àÊòØÂæû 1 ÈñãÂßãÁöÑÊ≠£Êï¥Êï∏)
                    - `Response Time (Minutes)`: ÊØèÈ°å‰ΩúÁ≠îÊôÇÈñì (ÂàÜÈêòÔºåÂøÖÈ†àÊòØÊ≠£Êï∏Ôºå‰æãÂ¶Ç 1.5 Êàñ 2)
                    - `Performance`: ‰ΩúÁ≠îË°®Áèæ (ÂøÖÈ†àÊòØ 'Correct' Êàñ 'Incorrect' ÈÄôÂÖ©Á®ÆÂ≠ó‰∏≤)
                - **ÁßëÁõÆÁâπÂÆöÊ¨Ñ‰Ωç:**
                    - `Content Domain` (Q Âíå DI ÁßëÁõÆÈúÄË¶Å):
                        - Q: 'Algebra' Êàñ 'Arithmetic'
                        - DI: 'Math Related' Êàñ 'Non-Math Related'
                    - `Question Type` (Q, V, DI ÈÉΩÈúÄË¶Å):
                        - Q: 'REAL' Êàñ 'PURE' (Ê≥®ÊÑèÊòØÂ§ßÂØ´)
                        - V: 'Critical Reasoning' Êàñ 'Reading Comprehension'
                        - DI: 'Data Sufficiency', 'Two-part analysis', 'Multi-source reasoning', 'Graph and Table' (Êàñ 'Graphs and Tables')
                    - `Fundamental Skills` (Q Âíå V ÁßëÁõÆÈúÄË¶Å):
                        - Q: ‰æãÂ¶Ç 'Rates/Ratio/Percent', 'Value/Order/Factors', 'Equal/Unequal/ALG', 'Counting/Sets/Series/Prob/Stats' (ÂÖÅË®±Â∏∏Ë¶ãÁöÑËã±ÊñáÂêåÁæ©Ë©ûÊàñÊ†ºÂºèËÆäÈ´îÔºåÁ≥ªÁµ±ÊúÉÂòóË©¶Ëá™ÂãïÊ†°Ê≠£)
                        - V: ‰æãÂ¶Ç 'Plan/Construct', 'Identify Stated Idea', 'Identify Inferred Idea', 'Analysis/Critique'
            - **ÈáçË¶ÅÔºöÂéªË≠òÂà•Âåñ (De-identification)**
                - **Âú®‰∏äÂÇ≥ÊàñË≤º‰∏äÊï∏ÊìöÂâçÔºåË´ãÂãôÂøÖ„ÄÅÂãôÂøÖ„ÄÅÂãôÂøÖ‰ªîÁ¥∞Ê™¢Êü•‰∏¶ÊâãÂãïÁßªÈô§ÊâÄÊúâÂèØËÉΩË≠òÂà•ÊÇ®ÂÄã‰∫∫Ë∫´‰ªΩÁöÑË≥áË®äÔºÅ** ÈÄôÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñºÔºöÊÇ®ÁöÑÂßìÂêç„ÄÅËÄÉÁîü ID (Candidate ID)„ÄÅËÄÉË©¶‰∏≠ÂøÉË≥áË®ä„ÄÅÈõªÂ≠êÈÉµ‰ª∂Âú∞ÂùÄÁ≠â„ÄÇ
                - ÊÇ®Â∞çÁ¢∫‰øùÊï∏ÊìöÂåøÂêçË≤†ÊúâÂÆåÂÖ®Ë≤¨‰ªª„ÄÇÊú¨Â∑•ÂÖ∑ÊúÉÊî∂ÈõÜÊÇ®‰∏äÂÇ≥ÁöÑÂåøÂêçÊï∏ÊìöÁî®ÊñºÊ®°ÂûãÊîπÈÄ≤ËàáÂàÜÊûê„ÄÇ

            **3. Â¶Ç‰Ωï‰ΩøÁî®Êú¨Â∑•ÂÖ∑Ôºö‰∏ÄÊ≠•Ê≠•ÊåáÂçó**

            - **Ê≠•È©ü‰∏ÄÔºöËº∏ÂÖ•Êï∏Êìö**
                - ÈªûÊìä‰∏äÊñπÁöÑÂàÜÈ†ÅÊ®ôÁ±§ÔºåÂàÜÂà•ÈÄ≤ÂÖ• Quantitative (Q), Verbal (V), Âíå Data Insights (DI) ÁöÑËº∏ÂÖ•ÂçÄ„ÄÇ
                - Âú®ÊØèÂÄãÂàÜÈ†Å‰∏≠ÔºåÈÅ∏Êìá„Äå‰∏äÂÇ≥ CSV Ê™îÊ°à„ÄçÊàñÂú®ÊñáÂ≠óÊ°Ü‰∏≠„ÄåË≤º‰∏ä Excel Ë≥áÊñô„Äç„ÄÇ
                - ÊàêÂäüËÆÄÂèñÂæåÔºå‰∏ãÊñπÊúÉÂá∫ÁèæÊï∏ÊìöÈ†êË¶ΩÂíåÁ∑®ËºØÂô®„ÄÇ
            - **Ê≠•È©ü‰∫åÔºöÈ†êË¶Ω„ÄÅÁ∑®ËºØËàáÊ®ôË®òÁÑ°ÊïàÊï∏Êìö**
                - Âú®Êï∏ÊìöÁ∑®ËºØÂô®‰∏≠ÔºåÊ™¢Êü•ÊÇ®ÁöÑÊï∏ÊìöÊòØÂê¶ËÆÄÂèñÊ≠£Á¢∫„ÄÇ
                - **ÈóúÈçµÊ≠•È©üÔºö** Â∞çÊñºÊÇ®Á¢∫ÂÆöÊòØÂõ†ÊôÇÈñìÂ£ìÂäõÈÅéÂ§ß„ÄÅÂÄâ‰øÉÁåúÊ∏¨„ÄÅÂàÜÂøÉÁ≠âÂéüÂõ†ËÄå„ÄåÈùûÊ≠£Â∏∏‰ΩúÁ≠î„ÄçÁöÑÈ°åÁõÆÔºåË´ãÂãæÈÅ∏Ë©≤Ë°åÊúÄÂ∑¶ÂÅ¥ÁöÑ **"ÊòØÂê¶ËçâÁéáÂÅöÈ°åÔºü (ÊâãÂãïÊ®ôË®ò)"** Ê†∏ÂèñÊñπÂ°ä„ÄÇÁ≥ªÁµ±ÂèØËÉΩÊúÉÊ†πÊìöÊôÇÈñìËá™ÂãïÈ†êÂÖàÂãæÈÅ∏ÈÉ®ÂàÜÈ°åÁõÆÔºå‰ΩÜÊÇ®ÁöÑÊâãÂãïÊ®ôË®òÊúÉÂÑ™ÂÖàÊé°Áî®„ÄÇ
                - ÊÇ®‰πüÂèØ‰ª•Âú®Á∑®ËºØÂô®‰∏≠Áõ¥Êé•‰øÆÊ≠£ÊòéÈ°ØÁöÑÊï∏ÊìöÈåØË™§„ÄÇ
            - **Ê≠•È©ü‰∏âÔºöË®≠ÂÆöÂàÜÊûêÂèÉÊï∏ (ÂÅ¥ÈÇäÊ¨Ñ)**
                - **IRT Ê®°Êì¨Ë®≠ÂÆöÔºö** ÊÇ®ÂèØ‰ª•Ë®≠ÂÆö Q, V, DI ÂêÑÁßëÁöÑÂàùÂßãËÉΩÂäõ‰º∞Ë®àÂÄº (Theta)„ÄÇÂ¶ÇÊûúÊÇ®‰∏çÁ¢∫ÂÆöÔºå**Âª∫Ë≠∞‰øùÁïôÈ†êË®≠ÂÄº 0.0**„ÄÇ
                - **OpenAI Ë®≠ÂÆö (ÈÅ∏Áî®)Ôºö** Â¶ÇÊûúÊÇ®ÊìÅÊúâ OpenAI API Key ‰∏¶Â∏åÊúõ‰ΩøÁî® AI ÂïèÁ≠îÂíåÂ†±ÂëäÊï¥ÁêÜÂäüËÉΩÔºåË´ãÂú®Ê≠§Ëº∏ÂÖ•„ÄÇÂê¶ÂâáË´ãÁïôÁ©∫„ÄÇ
            - **Ê≠•È©üÂõõÔºöÈñãÂßãÂàÜÊûê**
                - **ÈáçË¶ÅÔºö** Âè™ÊúâÁï∂ÊÇ®ÁÇ∫ **Q, V, DI ‰∏âÂÄãÁßëÁõÆÈÉΩÊàêÂäüËºâÂÖ•‰∫ÜÊúâÊïàÊï∏Êìö**ÔºàÈÄöÈÅéÈ©óË≠â‰∏îÁÑ°ÈåØË™§Ë®äÊÅØÔºâÂæåÔºå‰∏ªÈ†ÅÈù¢‰∏ãÊñπÁöÑ **"ÈñãÂßãÂàÜÊûê"** ÊåâÈàïÊâçÊúÉËÆäÁÇ∫ÂèØÁî®ÁãÄÊÖã„ÄÇ
                - Â¶ÇÊûúÊåâÈàï‰∏çÂèØÁî®ÔºåË´ãÊ™¢Êü•‰∏äÊñπÊòØÂê¶ÊúâÁ¥ÖËâ≤ÈåØË™§Ë®äÊÅØÊàñÁº∫Â∞ëÁßëÁõÆÁöÑÊèêÁ§∫„ÄÇ
                - ÈªûÊìä "ÈñãÂßãÂàÜÊûê" ÊåâÈàï„ÄÇÈ†ÅÈù¢ÊúÉÈ°ØÁ§∫ÈÄ≤Â∫¶Ê¢ùÂíåÁõÆÂâçÁöÑÂàÜÊûêÊ≠•È©ü„ÄÇË´ãÁ®çÂÄôÁâáÂàª„ÄÇ

            **4. ÁêÜËß£ÊÇ®ÁöÑË®∫Êñ∑Â†±Âëä**

            ÂàÜÊûêÂÆåÊàêÂæåÔºåÁµêÊûúÊúÉÈ°ØÁ§∫Âú®„ÄåÁµêÊûúÊü•Áúã„ÄçÊ®ôÁ±§È†Å‰∏≠Ôºö

            - **ÂêÑÁßëÁõÆÁµêÊûúÂàÜÈ†Å (‰æãÂ¶Ç "Q ÁßëÁµêÊûú")Ôºö**
                - **ËÉΩÂäõ‰º∞Ë®à (Theta) Ëµ∞Âã¢ÂúñÔºö** È°ØÁ§∫Á≥ªÁµ±Ê®°Êì¨Âá∫ÁöÑÊÇ®ÁöÑËÉΩÂäõÂÄº (Theta) Âú®‰ΩúÁ≠îÈÅéÁ®ã‰∏≠ÁöÑËÆäÂåñË∂®Âã¢„ÄÇÊõ≤Á∑öÂêë‰∏äË°®Á§∫ËÉΩÂäõ‰º∞Ë®àÂÄºÊèêÂçá„ÄÇ
                - **Ë®∫Êñ∑Â†±Âëä (ÊñáÂ≠óÊëòË¶Å)Ôºö** ‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÂëàÁèæË©≥Á¥∞ÁöÑÂàÜÊûêÁµêÊûúÔºåÂåÖÂê´Ôºö
                    - Êï¥È´îÊôÇÈñìÂ£ìÂäõË©ï‰º∞
                    - ÂêÑÁ∂≠Â∫¶ÔºàÂ¶ÇÈ°åÂûã„ÄÅÈõ£Â∫¶„ÄÅÊäÄËÉΩÔºâÁöÑË°®ÁèæÊ¶ÇË¶Ω
                    - Ê†∏ÂøÉÂïèÈ°åË®∫Êñ∑ÔºàÈåØË™§Ê®°Âºè„ÄÅSFE ‰∏çÁ©©ÂÆöÈªûÁ≠âÔºâ
                    - ÁâπÊÆäË°åÁÇ∫Ê®°ÂºèËßÄÂØüÔºàÂ¶ÇÈñãÈ†≠Êê∂Âø´„ÄÅÊΩõÂú®Á≤óÂøÉÁ≠âÔºâ
                    - ÈúÄË¶ÅÈûèÂõ∫ÁöÑÂü∫Á§éÁü•Ë≠òÈ†òÂüü
                    - ÂÄã‰∫∫ÂåñÁöÑÁ∑¥ÁøíË®àÂäÉËàáÂª∫Ë≠∞ (ÂåÖÂê´Âª∫Ë≠∞Èõ£Â∫¶ Y ÂíåËµ∑ÂßãÊôÇÈñì Z)
                - **Ë©≥Á¥∞Êï∏ÊìöË°®Ôºö** ÂåÖÂê´ÊÇ®Ëº∏ÂÖ•ÁöÑÊï∏ÊìöÔºå‰ª•ÂèäÁ≥ªÁµ±Ë®àÁÆóÂá∫ÁöÑË®∫Êñ∑Ê®ôÁ±§Ôºå‰æãÂ¶ÇÔºöÊ®°Êì¨Èõ£Â∫¶„ÄÅÊôÇÈñìË°®ÁèæÂàÜÈ°û (Âø´/ÊÖ¢/Ê≠£Â∏∏)„ÄÅÊòØÂê¶ SFE„ÄÅÊòØÂê¶Ë∂ÖÊôÇ„ÄÅÊòØÂê¶Ë¢´Ê®ôË®òÁÇ∫ÁÑ°ÊïàÁ≠â„ÄÇË°®Ê†ºÊúâÈ°èËâ≤Ê®ôÁ§∫ÔºöÁ¥ÖËâ≤ÊñáÂ≠óË°®Á§∫Á≠îÈåØÔºåËóçËâ≤ÊñáÂ≠óË°®Á§∫Áî®ÊôÇË∂ÖÊôÇÔºåÁÅ∞Ëâ≤ÊñáÂ≠óË°®Á§∫Ë©≤È°åË¢´Ê®ôË®òÁÇ∫ÁÑ°Êïà„ÄÇ
                - **‰∏ãËºâÊåâÈàïÔºö** ÊÇ®ÂèØ‰ª•Â∞áÂ∏∂ÊúâË®∫Êñ∑Ê®ôÁ±§ÁöÑË©≥Á¥∞Êï∏Êìö‰∏ãËºâÁÇ∫ Excel Ê™îÊ°àÔºåÊñπ‰æøÈõ¢Á∑öÊü•ÁúãÊàñËàáÊïôÂ∏´Ë®éË´ñ„ÄÇ
            - **‚ú® AI ÂåØÁ∏ΩÂª∫Ë≠∞ÂàÜÈ†Å (Ëã•ÊÇ®Êèê‰æõ‰∫Ü OpenAI Key ‰∏îÂàÜÊûêÊàêÂäü)Ôºö**
                - Ê≠§ÂàÜÈ†ÅÁî± AI (o4-mini Ê®°Âûã) Ëá™ÂãïÊï¥ÁêÜÁîüÊàê„ÄÇ
                - ÂÆÉÊúÉÂæû Q, V, DI ‰∏â‰ªΩÂ†±Âëä‰∏≠Ôºå**ÂÉÖÊèêÂèñ„ÄåÁ∑¥ÁøíÂª∫Ë≠∞„ÄçÂíå„ÄåÂæåÁ∫åË°åÂãï„Äç** ÈÄôÂÖ©ÂÄãÈÉ®ÂàÜÁöÑÂÖßÂÆπÔºåÂêà‰ΩµÂú®‰∏ÄËµ∑ÔºåÊñπ‰æøÊÇ®Âø´ÈÄüÊ¶ÇË¶ΩÊúÄÈáçË¶ÅÁöÑË°åÂãïÈ†ÖÁõÆ„ÄÇ
                - **Ê≥®ÊÑèÔºö** Ê≠§ÁÇ∫ AI ÊèêÂèñÁöÑÊëòË¶ÅÔºåË´ãÂãôÂøÖÂ∞çÁÖßÂêÑÁßëÁõÆÁöÑÂÆåÊï¥Â†±ÂëäÂéüÊñáÔºå‰ª•Á¢∫‰øùÁêÜËß£ÂÆåÊï¥„ÄÇ

            **5. AI ÂïèÁ≠îÂäüËÉΩ (Ëã•ÊÇ®Êèê‰æõ‰∫Ü OpenAI Key)**

            - Â¶ÇÊûúÂàÜÊûêÊàêÂäü‰∏îÊÇ®Ëº∏ÂÖ•‰∫ÜÊúâÊïàÁöÑ OpenAI API KeyÔºåÈ†ÅÈù¢ÊúÄ‰∏ãÊñπÊúÉÂá∫Áèæ‰∏ÄÂÄã**„ÄåËàá AI Â∞çË©±„Äç**ÁöÑËÅäÂ§©Ê°Ü„ÄÇ
            - ÊÇ®ÂèØ‰ª•ÈáùÂ∞ç**Êú¨Ê¨°ÁîüÊàêÁöÑÂ†±ÂëäÂÖßÂÆπÂíåË©≥Á¥∞Êï∏Êìö**Âêë AI ÊèêÂïè„ÄÇ‰æãÂ¶ÇÔºö
                - "Ë´ãËß£Èáã‰∏Ä‰∏ãÊàëÂú® Q ÁßëÁöÑ SFE ÈåØË™§ÊòØ‰ªÄÈ∫ºÊÑèÊÄùÔºü"
                - "V ÁßëÂ†±ÂëäË£°ÁöÑ 'Slow & Right' ÂÖ∑È´îÊåáÂì™ÂπæÈ°åÔºü"
                - "Âπ´ÊàëÁ∏ΩÁµê‰∏Ä‰∏ã DI ÁßëÁõÆÁöÑÁ∑¥ÁøíÂª∫Ë≠∞„ÄÇ"
                - "Á¨¨ 10 È°åÁöÑË®∫Êñ∑Ê®ôÁ±§ÊúâÂì™‰∫õÔºü"
            - **Ë´ãÊ≥®ÊÑèÔºö** AI ÁöÑÂõûÁ≠î**ÂÆåÂÖ®Âü∫Êñº**Êú¨Ê¨°ÂàÜÊûêÁî¢Âá∫ÁöÑÂ†±ÂëäÂíåÊï∏Êìö„ÄÇÂÆÉÁÑ°Ê≥ïÊèê‰æõË∂ÖÂá∫ÈÄô‰∫õË≥áË®äÁØÑÂúçÁöÑÈÄöÁî® GMAT Áü•Ë≠òÊàñÂª∫Ë≠∞„ÄÇ

            **6. Â∏∏Ë¶ãÂïèÈ°å (FAQ)**

            - **Q: "ÈñãÂßãÂàÜÊûê" ÊåâÈàïÁÇ∫‰ªÄÈ∫º‰∏çËÉΩÈªûÔºü**
                - A: Ë´ãÁ¢∫‰øùÊÇ®Â∑≤Á∂ìÂú® Q, V, DI ‰∏âÂÄãÂàÜÈ†ÅÈÉΩÊàêÂäü‰∏äÂÇ≥ÊàñË≤º‰∏ä‰∫ÜÊï∏ÊìöÔºå‰∏¶‰∏îÈ†ÅÈù¢‰∏äÊñπÊ≤íÊúâÈ°ØÁ§∫Á¥ÖËâ≤ÁöÑÈ©óË≠âÈåØË™§Ë®äÊÅØ„ÄÇÂøÖÈ†à‰∏âÂÄãÁßëÁõÆÈÉΩÊúâÊúâÊïàÊï∏ÊìöÊâçËÉΩÈñãÂßã„ÄÇ
            - **Q: Êàë‰∏äÂÇ≥/Ë≤º‰∏äÁöÑÊï∏ÊìöÂ•ΩÂÉèËÆÄÂèñ‰∏çÂ∞çÊàñÂ†±ÈåØÔºü**
                - A: Ë´ã‰ªîÁ¥∞Ê™¢Êü•ÊÇ®ÁöÑÊï∏ÊìöÊ†ºÂºèÊòØÂê¶Á¨¶ÂêàÁ¨¨ 2 ÁØÄÁöÑË¶ÅÊ±ÇÔºåÁâπÂà•ÊòØÊ¨Ñ‰ΩçÊ®ôÈ°åÊòØÂê¶ÂÆåÂÖ®‰∏ÄËá¥„ÄÅÊï∏ÊìöÈ°ûÂûãÊòØÂê¶Ê≠£Á¢∫ÔºàÊôÇÈñìÊòØÊï∏Â≠ó„ÄÅË°®ÁèæÊòØ'Correct'/'Incorrect'Á≠âÔºâ„ÄÇÂ∏∏Ë¶ãÈåØË™§ÂåÖÂê´ÔºöÊ¨Ñ‰ΩçÊ®ôÈ°åÊâìÈåØÂ≠ó„ÄÅÂ§ö‰∫ÜÁ©∫Ê†º„ÄÅCSV ÈÄóËôü‰ΩøÁî®‰∏çÁï∂„ÄÅË≤º‰∏äÊôÇÊ†ºÂºèÊ∑∑‰∫ÇÁ≠â„ÄÇ
            - **Q: Â†±ÂëäË£°ÁöÑ„ÄåÈõ£Â∫¶„ÄçÊòØÊÄéÈ∫º‰æÜÁöÑÔºü**
                - A: ÈÄôÂÄãÈõ£Â∫¶ÊòØÂ∑•ÂÖ∑ÂÖßÈÉ®ÈÄèÈÅé IRT Ê®°Êì¨ÊºîÁÆóÊ≥ïÔºåÊ†πÊìöÊÇ®ÁöÑ‰ΩúÁ≠îÊ®°ÂºèÔºàÂ∞çÈåØÈ†ÜÂ∫èÔºâ‰º∞Ë®àÂá∫‰æÜÁöÑÁõ∏Â∞çÈõ£Â∫¶ÂÄºÔºåÂÉÖÁî®ÊñºÊú¨Ê¨°Ë®∫Êñ∑ÂàÜÊûêÔºå‰∏¶ÈùûÂÆòÊñπÂÖ¨‰ΩàÁöÑÈ°åÁõÆÈõ£Â∫¶„ÄÇ
            - **Q: AI ÂäüËÉΩÔºàÂåØÁ∏ΩÂª∫Ë≠∞„ÄÅÂ∞çË©±ÔºâÁÑ°Ê≥ï‰ΩøÁî®Ôºü**
                - A: Ë´ãÊ™¢Êü•ÊÇ®ÊòØÂê¶Âú®ÂÅ¥ÈÇäÊ¨ÑËº∏ÂÖ•‰∫ÜÊúâÊïàÁöÑ OpenAI API Key„ÄÇÂêåÊôÇÔºåAI ÂäüËÉΩÂÉÖÂú®‰∏ªÂàÜÊûêÊàêÂäüÂÆåÊàêÂæåÊâçÊúÉÂïüÁî®„ÄÇÂ¶ÇÊûúÂàÜÊûêÂ§±ÊïóÔºåAI ÂäüËÉΩ‰πüÁÑ°Ê≥ï‰ΩøÁî®„ÄÇ
            """)
        
        st.divider()
        
        # --- Data Input Section ---
        input_dfs, validation_errors, data_source_types = setup_input_tabs(preprocess_helpers)
        
        # Ê™¢Êü•ÊòØÂê¶ÈúÄË¶ÅÈ°ØÁ§∫ÁØÑ‰æãÊï∏Êìö
        if st.session_state.get('example_data_loaded', False) and st.session_state.get('example_data'):
            # Ê≥®ÂÖ•ÁØÑ‰æãÊï∏ÊìöÂà∞input_dfs
            for subject in SUBJECTS:
                if subject in st.session_state['example_data']:
                    if input_dfs.get(subject) is None:  # Âè™ÊúâÂú®Â∞öÊú™Ëº∏ÂÖ•Êï∏ÊìöÊôÇÊâçÊ≥®ÂÖ•
                        example_df = st.session_state['example_data'][subject].copy()
                        # Ê∑ªÂä†ÂøÖË¶ÅÁöÑÂàó
                        example_df['is_manually_invalid'] = False
                        example_df['Subject'] = subject
                        
                        # ÈáçË®≠Á¥¢Âºï‰ª•ÈÅøÂÖçÊΩõÂú®ÁöÑÁ¥¢ÂºïÂïèÈ°å
                        example_df = example_df.reset_index(drop=True)
                        
                        # Â∞áÂéüÂßãÊï∏ÊìöÈáçÂëΩÂêçÁÇ∫Ê®ôÊ∫ñÂåñÂàóÂêç
                        rename_map = BASE_RENAME_MAP.copy()
                        if 'Question' in example_df.columns:
                            rename_map['Question'] = 'question_position'
                        if 'Response Time (Minutes)' in example_df.columns:
                            rename_map['Response Time (Minutes)'] = 'question_time'
                        if 'Performance' in example_df.columns:
                            rename_map['Performance'] = 'is_correct'
                            # ËΩâÊèõPerformanceÂàóÁÇ∫is_correct
                            example_df['is_correct'] = example_df['Performance'].apply(
                                lambda x: x == 'Correct' if isinstance(x, str) else bool(x)
                            )
                        
                        example_df.rename(columns=rename_map, inplace=True)
                        
                        input_dfs[subject] = example_df
                        validation_errors[subject] = []
                        data_source_types[subject] = "ÁØÑ‰æãÊï∏Êìö"
            
            # Ê∏ÖÈô§Ê®ôË™åÔºåÈÅøÂÖçÈáçË§áÂä†Ëºâ
            st.session_state['example_data_loaded'] = False
        
        # Store in session state
        st.session_state.input_dfs = input_dfs
        st.session_state.validation_errors = validation_errors
        st.session_state.data_source_types = data_source_types
        
        # Combine Input Data
        df_combined_input, loaded_subjects, valid_input_dfs = combine_input_data(input_dfs, SUBJECTS)
        
        # Check if any validation errors occurred across all tabs
        any_validation_errors = any(bool(warnings) for warnings in validation_errors.values())
        
        # Display Analysis Button with improved styling
        st.divider()
        st.subheader("3. ÈñãÂßãÂàÜÊûê")
        button_clicked, button_disabled, button_message = display_analysis_button(
            df_combined_input, 
            any_validation_errors, 
            input_dfs,
            SUBJECTS
        )
        
        # --- Analysis Execution Block ---
        if button_clicked and not button_disabled:
            # This is a new analysis request
            reset_session_for_new_upload() # Clear previous *results* and *completion status*
            st.session_state.analysis_run = True # Mark that analysis should run *now*
                                               # This flag will persist for the current script run
                                               # to ensure results are displayed.
            st.session_state.diagnosis_complete = False # Ensure it starts as not complete

            if df_combined_input is not None:
                with st.spinner("Ê≠£Âú®Âü∑Ë°å IRT Ê®°Êì¨ËàáË®∫Êñ∑..."):
                    # --- Add to CSV ---
                    records_to_add = []
                    # Generate a unique student_id for this upload session if not available
                    # For simplicity, using a fixed student_id for now, or derive from session
                    student_id_for_batch = st.session_state.get("student_id_for_upload", f"student_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}")
                    st.session_state.student_id_for_upload = student_id_for_batch # Store for potential reuse in the session
                    
                    test_date_for_batch = datetime.date.today().isoformat()

                    # Calculate per-section totals first
                    section_stats = {}
                    if 'Subject' in df_combined_input.columns and 'question_time' in df_combined_input.columns:
                        for subject_name, group in df_combined_input.groupby('Subject'):
                            if subject_name in SUBJECTS: # Process only Q, V, DI
                                # Ensure question_time is numeric before summing
                                numeric_times = pd.to_numeric(group['question_time'], errors='coerce')
                                section_stats[subject_name] = {
                                    'total_questions': len(group),
                                    'total_time': numeric_times.sum()
                                }

                    for index, row in df_combined_input.iterrows():
                        record = {}
                        gmat_section = row.get("Subject")
                        
                        # Skip if not a main GMAT section (e.g. 'Total' if it exists in df_combined_input)
                        if gmat_section not in SUBJECTS:
                            continue
                            
                        record["student_id"] = student_id_for_batch
                        # Create a unique test_instance_id for each section within the batch
                        record["test_instance_id"] = f"{student_id_for_batch}_{gmat_section}_{test_date_for_batch.replace('-', '')}_upload"
                        record["gmat_section"] = gmat_section
                        record["test_date"] = test_date_for_batch
                        
                        question_pos = row.get("question_position", index + 1)
                        record["question_id"] = f"{gmat_section}_{question_pos}_{test_date_for_batch.replace('-', '')}"
                        record["question_position"] = int(question_pos) if pd.notnull(question_pos) else index + 1
                        # Ensure question_time is numeric before converting to float
                        question_time_val = row.get("question_time", 0.0)
                        if isinstance(question_time_val, str):
                            question_time_val = pd.to_numeric(question_time_val, errors='coerce')
                        record["question_time_minutes"] = float(question_time_val) if pd.notnull(question_time_val) else 0.0
                        
                        is_correct_val = row.get("is_correct")
                        if isinstance(is_correct_val, bool):
                            record["is_correct"] = 1 if is_correct_val else 0
                        elif isinstance(is_correct_val, str):
                            record["is_correct"] = 1 if is_correct_val.lower() == 'correct' else 0
                        else:
                            record["is_correct"] = 0 # Default if unknown format
                            
                        # question_difficulty might not be present in uploaded data, default to 0 or a placeholder
                        record["question_difficulty"] = float(row.get("question_difficulty", 0.0)) 
                        record["question_type"] = str(row.get("question_type", ""))
                        record["question_fundamental_skill"] = str(row.get("question_fundamental_skill", ""))
                        record["content_domain"] = str(row.get("content_domain", ""))
                        
                        if gmat_section in section_stats:
                            record["total_questions_in_section"] = int(section_stats[gmat_section]['total_questions'])
                            # Safely convert total_time to float, handle NaN values
                            total_time_val = section_stats[gmat_section]['total_time']
                            record["total_section_time_minutes"] = float(total_time_val) if pd.notnull(total_time_val) else 0.0
                        else:
                            record["total_questions_in_section"] = 0 # Should not happen if Subject is Q,V,DI
                            record["total_section_time_minutes"] = 0.0

                        record["max_allowed_section_time_minutes"] = 45.0 # Standard or from config
                        
                        # Ensure all GMAT_PERFORMANCE_HEADERS are present, even if with None or default values, except record_timestamp
                        for header in GMAT_PERFORMANCE_HEADERS:
                            if header not in record and header != "record_timestamp":
                                record[header] = None 
                        records_to_add.append(record)
                    
                    if records_to_add:
                        if add_gmat_performance_record(records_to_add):
                            # st.toast(f"Â∑≤ÊàêÂäüÂ∞á {len(records_to_add)} Á≠ÜË≥áÊñôÈôÑÂä†Âà∞ gmat_performance_data.csv", icon="‚úÖ") # This line will be commented out
                            pass # Add pass if commenting out the toast makes the block empty
                        else:
                            st.toast("ÈôÑÂä†Ë≥áÊñôÂà∞ gmat_performance_data.csv ÊôÇÁôºÁîüÈåØË™§„ÄÇ", icon="‚ö†Ô∏è")
                    else:
                        st.toast("Ê≤íÊúâÂèØÈôÑÂä†Âà∞ gmat_performance_data.csv ÁöÑË≥áÊñô„ÄÇ", icon="‚ÑπÔ∏è")
                    # --- End Add to CSV ---
                    
                    # --- Ê∑ªÂä†‰∏ªËßÄÊôÇÈñìÂ£ìÂäõÂ†±ÂëäÂà∞ CSV ---
                    subjective_reports_added = 0
                    
                    for subject in SUBJECTS:
                        subject_key = subject.lower()
                        time_pressure_key = f"{subject_key}_time_pressure"
                        
                        if time_pressure_key in st.session_state:
                            time_pressure_value = int(st.session_state[time_pressure_key])
                            test_instance_id = f"{student_id_for_batch}_{subject}_{test_date_for_batch.replace('-', '')}_upload"
                            
                            # ÂâµÂª∫‰∏ªËßÄÂ†±ÂëäË®òÈåÑ
                            subjective_report = {
                                "student_id": student_id_for_batch,
                                "test_instance_id": test_instance_id,
                                "gmat_section": subject,
                                "subjective_time_pressure": time_pressure_value,
                                "report_collection_timestamp": datetime.datetime.now().isoformat()
                            }
                            
                            # Â∞áÂ†±ÂëäÂØ´ÂÖ• CSV
                            if add_subjective_report_record(subjective_report):
                                subjective_reports_added += 1
                            else:
                                st.toast(f"Ê∑ªÂä† {subject} ÁßëÁõÆÁöÑ‰∏ªËßÄÊôÇÈñìÂ£ìÂäõÂ†±ÂëäÂà∞ CSV ÊôÇÁôºÁîüÈåØË™§„ÄÇ", icon="‚ö†Ô∏è")
                    
                    if subjective_reports_added > 0:
                        pass # ÊàêÂäüÊ∑ªÂä†Â†±Âëä
                    # --- Ê∑ªÂä†‰∏ªËßÄÊôÇÈñìÂ£ìÂäõÂ†±ÂëäÂà∞ CSV ÁµêÊùü ---

                    run_analysis(df_combined_input) # This will update diagnosis_complete and analysis_error
                
                if st.session_state.diagnosis_complete:
                    st.success("ÂàÜÊûêÂÆåÊàêÔºÅË´ãÂâçÂæÄÈ†ÅÈ¶ñÁöÑ„ÄåÁµêÊûúÊü•Áúã„ÄçÂàÜÈ†ÅÊü•ÁúãË®∫Êñ∑ÁµêÊûú„ÄÇ")
            else:
                # If there's no data, then analysis didn't really "run" in a meaningful way.
                st.session_state.analysis_run = False 
                st.error("Ê≤íÊúâÂêà‰ΩµÁöÑÊï∏ÊìöÂèØ‰ª•ÂàÜÊûêÔºåÁÑ°Ê≥ïÂïüÂãïÂàÜÊûê„ÄÇ")
    
    with main_tabs[1]:  # ÁµêÊûúÊü•ÁúãÊ®ôÁ±§È†Å
        if st.session_state.get("diagnosis_complete", False):
            display_results()
        else:
            # È°ØÁ§∫Â∞öÊú™ÂàÜÊûêÁöÑÊèêÁ§∫
            st.info("Â∞öÊú™Âü∑Ë°åÂàÜÊûê„ÄÇË´ãÂÖàÂú®„ÄåÊï∏ÊìöËº∏ÂÖ•ËàáÂàÜÊûê„ÄçÊ®ôÁ±§‰∏≠‰∏äÂÇ≥Êï∏Êìö‰∏¶Âü∑Ë°åÂàÜÊûê„ÄÇ")
            st.markdown("""
            ### ÂàÜÊûêÊµÅÁ®ãË™™Êòé
            
            1. Âú®„ÄåÊï∏ÊìöËº∏ÂÖ•ËàáÂàÜÊûê„ÄçÊ®ôÁ±§‰∏≠‰∏äÂÇ≥‰∏âÂÄãÁßëÁõÆÁöÑÊï∏Êìö
            2. Á¢∫‰øùÊï∏ÊìöÊ†ºÂºèÊ≠£Á¢∫‰∏¶ÈÄöÈÅéÈ©óË≠â
            3. ÈªûÊìä„ÄåÈñãÂßãÂàÜÊûê„ÄçÊåâÈàï
            4. ÂàÜÊûêÂÆåÊàêÂæåÔºåÁµêÊûúÂ∞áÈ°ØÁ§∫Âú®Ê≠§È†ÅÈù¢
            """)
            
    # --- Sidebar Settings ---
    st.sidebar.subheader("ÂàÜÊûêË®≠ÂÆö")
    
    # Ê∑ªÂä†ÁØÑ‰æãÊï∏ÊìöÂ∞éÂÖ•ÂäüËÉΩ
    with st.sidebar.expander("üìä ÁØÑ‰æãÊï∏Êìö", expanded=True):
        st.markdown("### ÁØÑ‰æãÊï∏ÊìöÂ∞éÂÖ•")
        st.markdown("ÈªûÊìä‰∏ãÊñπÊåâÈàïÂ∞éÂÖ•ÁØÑ‰æãÂÅöÈ°åÊï∏ÊìöÔºåÊñπ‰æøÈ´îÈ©óÁ≥ªÁµ±ÂäüËÉΩ")
        
        st.button("‰∏ÄÈçµÂ∞éÂÖ•ÁØÑ‰æãÊï∏Êìö", 
                  key="load_sample_data_pasted", 
                  use_container_width=True,
                  on_click=load_sample_data_callback) # Use on_click callback

        if st.session_state.get('sample_data_pasted_success', False):
            st.success("ÁØÑ‰æãÊï∏ÊìöÂ∑≤ÊàêÂäüÂ°´ÂÖ•ÂêÑÁßëÁõÆÁöÑÊñáÊú¨Ê°ÜÔºÅË´ãÊ™¢Êü•„ÄåÊï∏ÊìöËº∏ÂÖ•ËàáÂàÜÊûê„ÄçÈ†ÅÈù¢„ÄÇ")
            st.session_state.sample_data_pasted_success = False # Reset flag
            
    # OpenAIË®≠ÂÆöÂçÄÂ°äÔºàÁßªÂà∞‰∏äÊñπÊõ¥ÊòéÈ°ØÁöÑ‰ΩçÁΩÆÔºâ
    with st.sidebar.expander("ü§ñ AIÂäüËÉΩË®≠ÂÆö", expanded=False):
        master_key_input = st.text_input(
            "Ëº∏ÂÖ•ÁÆ°ÁêÜÂì°ÈáëÈë∞ÂïüÁî® AI ÂïèÁ≠îÂäüËÉΩÔºö",
            type="password",
            key="master_key_input",
            value=st.session_state.get('master_key', ''),
            help="Ëº∏ÂÖ•ÊúâÊïàÁÆ°ÁêÜÈáëÈë∞‰∏¶ÊàêÂäüÂÆåÊàêÂàÜÊûêÂæåÔºå‰∏ãÊñπÂ∞áÂá∫Áèæ AI Â∞çË©±Ê°Ü„ÄÇÁÆ°ÁêÜÈáëÈë∞Ë´ãÂêëÁ≥ªÁµ±ÁÆ°ÁêÜÂì°Á¥¢Âèñ„ÄÇ"
        )

        # Update session state when input changes
        if master_key_input:
            st.session_state.master_key = master_key_input
            # ‰ΩøÁî®Êñ∞ÁöÑÊñπÊ≥ïÂü∫Êñºmaster keyÂàùÂßãÂåñOpenAIÂÆ¢Êà∂Á´Ø
            from gmat_diagnosis_app.services.openai_service import initialize_openai_client_with_master_key
            if initialize_openai_client_with_master_key(master_key_input):
                st.session_state.show_chat = True
                st.session_state.chat_history = []
                st.success("ÁÆ°ÁêÜÈáëÈë∞È©óË≠âÊàêÂäüÔºåAIÂäüËÉΩÂ∑≤ÂïüÁî®ÔºÅ")
            else:
                st.session_state.show_chat = False
                st.session_state.chat_history = []
                st.error("ÁÆ°ÁêÜÈáëÈë∞È©óË≠âÂ§±ÊïóÔºåÁÑ°Ê≥ïÂïüÁî®AIÂäüËÉΩ„ÄÇ")
        else:
            st.session_state.master_key = None
            st.session_state.show_chat = False
            st.session_state.chat_history = []

    # --- IRT Simulation Settings ---
    with st.sidebar.expander("üìä IRTÊ®°Êì¨Ë®≠ÂÆö", expanded=False):
        st.session_state.initial_theta_q = st.number_input(
            "Q ÁßëÁõÆÂàùÂßã Theta ‰º∞Ë®à", 
            value=st.session_state.initial_theta_q, 
            step=0.1,
            key="theta_q_input"
        )
        st.session_state.initial_theta_v = st.number_input(
            "V ÁßëÁõÆÂàùÂßã Theta ‰º∞Ë®à", 
            value=st.session_state.initial_theta_v, 
            step=0.1,
            key="theta_v_input"
        )
        st.session_state.initial_theta_di = st.number_input(
            "DI ÁßëÁõÆÂàùÂßã Theta ‰º∞Ë®à", 
            value=st.session_state.initial_theta_di, 
            step=0.1,
            key="theta_di_input"
        )

    # --- Manual IRT Adjustment Inputs in Sidebar ---
    with st.sidebar.expander("üîß ÊâãÂãïË™øÊï¥È°åÁõÆ", expanded=False):
        st.markdown("#### ÊâãÂãïË™øÊï¥È°åÁõÆÊ≠£Á¢∫ÊÄß")
        st.markdown("ÔºàÂÉÖÂΩ±ÈüøIRTÊ®°Êì¨Ôºâ")
        
        # ‰ΩøÁî®Ê®ôÁ±§È†ÅÁØÄÁúÅÁ©∫Èñì
        q_tab, v_tab, di_tab = st.tabs(["Q", "V", "DI"])
        
        with q_tab:
            st.session_state.q_incorrect_to_correct_qns = st.text_input(
                "Áî±ÈåØÊîπÂ∞çÈ°åËôü", 
                value=st.session_state.q_incorrect_to_correct_qns,
                placeholder="‰æã: 1,5,10",
                key="q_i_to_c_input"
            )
            st.session_state.q_correct_to_incorrect_qns = st.text_input(
                "Áî±Â∞çÊîπÈåØÈ°åËôü", 
                value=st.session_state.q_correct_to_incorrect_qns,
                placeholder="‰æã: 2,7,12",
                key="q_c_to_i_input"
            )
        
        with v_tab:
            st.session_state.v_incorrect_to_correct_qns = st.text_input(
                "Áî±ÈåØÊîπÂ∞çÈ°åËôü", 
                value=st.session_state.v_incorrect_to_correct_qns,
                placeholder="‰æã: 1,5,10",
                key="v_i_to_c_input"
            )
            st.session_state.v_correct_to_incorrect_qns = st.text_input(
                "Áî±Â∞çÊîπÈåØÈ°åËôü", 
                value=st.session_state.v_correct_to_incorrect_qns,
                placeholder="‰æã: 2,7,12",
                key="v_c_to_i_input"
            )
        
        with di_tab:
            st.session_state.di_incorrect_to_correct_qns = st.text_input(
                "Áî±ÈåØÊîπÂ∞çÈ°åËôü", 
                value=st.session_state.di_incorrect_to_correct_qns,
                placeholder="‰æã: 1,5,10",
                key="di_i_to_c_input"
            )
            st.session_state.di_correct_to_incorrect_qns = st.text_input(
                "Áî±Â∞çÊîπÈåØÈ°åËôü", 
                value=st.session_state.di_correct_to_incorrect_qns,
                placeholder="‰æã: 2,7,12",
                key="di_c_to_i_input"
            )
    
    # È†ÅÂ∞æ‰ø°ÊÅØ
    st.markdown("---")
    st.caption("ÊúâÂïèÈ°åÊàñÂª∫Ë≠∞ÔºüË´ãÂâçÂæÄ [GitHub Issues](https://github.com/danyuchn/GMAT-score-report-analysis/issues) Êèê‰∫§ÂèçÈ•ã")

if __name__ == "__main__":
    main() 