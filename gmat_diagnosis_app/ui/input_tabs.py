"""
è¼¸å…¥æ¨™ç±¤é æ¨¡çµ„
æä¾›æ•¸æ“šè¼¸å…¥å’Œæ¨™ç±¤é ç•Œé¢çš„åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
from gmat_diagnosis_app.utils.data_processing import process_subject_tab
from gmat_diagnosis_app.constants.config import (
    SUBJECTS,
    BASE_RENAME_MAP,
    MAX_FILE_SIZE_BYTES, 
    REQUIRED_ORIGINAL_COLS
)

def setup_input_tabs(preprocess_helpers_module):
    """è¨­ç½®è¼¸å…¥æ¨™ç±¤é ï¼Œè™•ç†æ•¸æ“šè¼¸å…¥å’Œé©—è­‰"""
    st.header("1. ä¸Šå‚³æˆ–è²¼ä¸Šå„ç§‘æˆç¸¾å–®")
    st.info(f"æç¤ºï¼šä¸Šå‚³çš„ CSV æª”æ¡ˆå¤§å°è«‹å‹¿è¶…é {MAX_FILE_SIZE_BYTES // (1024*1024)}MBã€‚è²¼ä¸Šçš„è³‡æ–™æ²’æœ‰æ­¤é™åˆ¶ã€‚")

    tab_q, tab_v, tab_di, tab_total = st.tabs(["Quantitative (Q)", "Verbal (V)", "Data Insights (DI)", "Total"])
    tabs = {'Q': tab_q, 'V': tab_v, 'DI': tab_di, 'Total': tab_total}

    # ç²å–é©—è­‰å’Œå»ºè­°ç„¡æ•ˆé¡Œç›®çš„å‡½æ•¸
    suggest_invalid_questions = preprocess_helpers_module.suggest_invalid_questions
    
    # Process each subject tab using the refactored function
    from gmat_diagnosis_app.utils.validation import validate_dataframe
    
    input_dfs = {}
    validation_errors = {}
    data_source_types = {}
    
    # è¨­ç½®Totalæ¨™ç±¤é 
    with tab_total:
        st.subheader("ä½¿ç”¨æ»‘ç«¿é¸æ“‡ç¸½åˆ†å’Œå„ç§‘ç´šåˆ†")
        st.markdown("æœ¬åŠŸèƒ½å¯æ ¹æ“šé¸æ“‡çš„åˆ†æ•¸ç”Ÿæˆç›¸æ‡‰çš„ç™¾åˆ†ä½æ•¸å’Œæ›²ç·šåœ–")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ç¸½åˆ†è¨­å®š")
            total_score = st.slider(
                "GMATç¸½åˆ† (205-805)",
                min_value=205,
                max_value=805,
                value=505,
                step=10,
                key="total_score_slider"
            )
            
            # å°‡é¸æ“‡çš„åˆ†æ•¸å­˜å…¥session state
            if "total_score" not in st.session_state or st.session_state.total_score != total_score:
                st.session_state.total_score = total_score
        
        with col2:
            st.markdown("### å„ç§‘ç´šåˆ†è¨­å®š")
            q_score = st.slider(
                "Qç§‘ç´šåˆ† (60-90)",
                min_value=60,
                max_value=90,
                value=75,
                step=1,
                key="q_score_slider"
            )
            
            v_score = st.slider(
                "Vç§‘ç´šåˆ† (60-90)",
                min_value=60,
                max_value=90,
                value=75,
                step=1,
                key="v_score_slider"
            )
            
            di_score = st.slider(
                "DIç§‘ç´šåˆ† (60-90)",
                min_value=60,
                max_value=90,
                value=75,
                step=1,
                key="di_score_slider"
            )
            
            # å°‡å„ç§‘ç´šåˆ†å­˜å…¥session state
            if "q_score" not in st.session_state or st.session_state.q_score != q_score:
                st.session_state.q_score = q_score
            if "v_score" not in st.session_state or st.session_state.v_score != v_score:
                st.session_state.v_score = v_score
            if "di_score" not in st.session_state or st.session_state.di_score != di_score:
                st.session_state.di_score = di_score
        
        # å‰µå»ºä¸€å€‹ç¤ºä¾‹DataFrameä»¥ä¾›é¡¯ç¤º
        if st.button("ç¢ºèªåˆ†æ•¸è¨­å®š", key="confirm_total_scores"):
            # å‰µå»ºä¸€å€‹åŒ…å«é¸å®šåˆ†æ•¸çš„DataFrame
            data = {
                'Score_Type': ['Total Score', 'Q Scaled Score', 'V Scaled Score', 'DI Scaled Score'],
                'Score': [total_score, q_score, v_score, di_score]
            }
            score_df = pd.DataFrame(data)
            
            # å°‡åˆ†æ•¸DataFrameå­˜å…¥session state
            st.session_state.score_df = score_df
            
            # é¡¯ç¤ºæ‰€é¸åˆ†æ•¸
            st.write("å·²é¸æ“‡çš„åˆ†æ•¸:")
            st.dataframe(score_df, hide_index=True)
            
            # å­˜å…¥input_dfsä»¥ä¾›å¾ŒçºŒè™•ç†
            # æ³¨æ„ï¼šé€™è£¡å‰µå»ºä¸€å€‹ç‰¹æ®Šæ ¼å¼çš„DataFrameï¼Œä»¥ä¾¿å¾ŒçºŒè™•ç†
            total_df = pd.DataFrame({
                'question_position': [1],  # è™›æ“¬çš„é¡Œè™Ÿ
                'is_manually_invalid': [False],
                'Subject': ['Total'],
                'total_score': [total_score],
                'q_score': [q_score],
                'v_score': [v_score],
                'di_score': [di_score]
            })
            
            input_dfs['Total'] = total_df
            validation_errors['Total'] = []
            data_source_types['Total'] = "æ»‘ç«¿è¨­å®š"
    
    # è™•ç†å…¶ä»–ä¸»é¡Œæ¨™ç±¤é 
    for subject in SUBJECTS:
        tab_container = tabs[subject]
        with tab_container:
            processed_df, source_type, warnings = process_subject_tab(
                subject, 
                tab_container, 
                BASE_RENAME_MAP, 
                MAX_FILE_SIZE_BYTES, 
                suggest_invalid_questions, 
                validate_dataframe,
                REQUIRED_ORIGINAL_COLS
            )
            
            # Store results in session state immediately after processing each tab
            input_dfs[subject] = processed_df  # Will be None if error/no data
            validation_errors[subject] = warnings
            if source_type:
                data_source_types[subject] = source_type
    
    return input_dfs, validation_errors, data_source_types

def combine_input_data(input_dfs, SUBJECTS):
    """Combine valid input DataFrames from all subjects"""
    # èª¿è©¦ä¿¡æ¯ï¼šæ‰“å°è¼¸å…¥çš„æ•¸æ“šæ¡†å­—å…¸
    # st.write("èª¿è©¦ï¼šè¼¸å…¥çš„æ•¸æ“šæ¡†") # Removed
    # for subj, df in input_dfs.items(): # Removed block
    #     if df is not None:
    #         st.write(f"ç§‘ç›® {subj}: å½¢ç‹€ {df.shape}, ç´¢å¼• {type(df.index)}, ç´¢å¼•ç¯„åœ {df.index.min()} - {df.index.max()}") # Removed
    #         if not df.index.is_unique:
    #             st.error(f"è­¦å‘Šï¼šç§‘ç›® {subj} çš„æ•¸æ“šæ¡†æœ‰é‡è¤‡ç´¢å¼•ï¼") # Kept error as it might be useful
    #             st.write(f"é‡è¤‡ç´¢å¼•å€¼ï¼š{df.index[df.index.duplicated()].tolist()}") # Kept error detail
    
    # Filter out subjects where df is None (error, no data, or validation failed)
    valid_input_dfs = {subj: df for subj, df in input_dfs.items() if df is not None and subj in SUBJECTS}
    loaded_subjects = list(valid_input_dfs.keys())  # Subjects with valid dataframes
    
    # èª¿è©¦ä¿¡æ¯ï¼šæ‰“å°æœ‰æ•ˆçš„æ•¸æ“šæ¡†
    # st.write(f"æœ‰æ•ˆç§‘ç›®: {loaded_subjects}") # Removed
    
    # å°‡Totalé ç±¤çš„æ•¸æ“šå–®ç¨å­˜å„²ï¼Œä¸èˆ‡å…¶ä»–ç§‘ç›®åˆä½µ
    if 'Total' in input_dfs and input_dfs['Total'] is not None:
        st.session_state.total_data = input_dfs['Total']
        # st.write("å·²ä¿å­˜Totalæ•¸æ“šåˆ°session state") # Removed

    df_combined_input = None
    if len(valid_input_dfs) == len(SUBJECTS):  # Only combine if ALL subjects are valid
        try:
            # èª¿è©¦ï¼šæ›´è©³ç´°åœ°æª¢æŸ¥æ¯å€‹æ•¸æ“šæ¡†
            # st.write("æº–å‚™åˆä½µçš„æ•¸æ“šæ¡†è©³æƒ…:") # Removed
            df_list = []
            
            for subj in SUBJECTS:
                if subj in valid_input_dfs:
                    df = valid_input_dfs[subj]
                    # st.write(f"ç§‘ç›® {subj} è©³æƒ…:") # Removed block
                    # st.write(f"  - å½¢ç‹€: {df.shape}") # Removed
                    # st.write(f"  - åˆ—å: {df.columns.tolist()}") # Removed
                    # st.write(f"  - ç´¢å¼•é¡å‹: {type(df.index)}") # Removed
                    # st.write(f"  - ç´¢å¼•æ˜¯å¦å”¯ä¸€: {df.index.is_unique}") # Removed
                    
                    # å…ˆé‡è¨­ç´¢å¼•ï¼Œç¢ºä¿æ²’æœ‰é‡è¤‡ç´¢å¼•
                    temp_df = df.copy()

                    # Check for and remove duplicate columns
                    if temp_df.columns.has_duplicates:
                        duplicated_cols = temp_df.columns[temp_df.columns.duplicated(keep=False)].unique().tolist()
                        st.warning(f"ç§‘ç›® {subj} ç™¼ç¾é‡è¤‡æ¬„ä½åç¨±: {duplicated_cols}. å°‡åªä¿ç•™æ¯å€‹æ¬„ä½çš„ç¬¬ä¸€æ¬¡å‡ºç¾ã€‚")
                        temp_df = temp_df.loc[:, ~temp_df.columns.duplicated(keep='first')]
                        # st.write(f"  - å»é™¤é‡è¤‡æ¬„ä½å¾Œåˆ—å: {temp_df.columns.tolist()}") # Removed
                        # st.write(f"  - å»é™¤é‡è¤‡æ¬„ä½å¾Œå½¢ç‹€: {temp_df.shape}") # Removed
                    
                    temp_df = temp_df.reset_index(drop=True)
                    # st.write(f"  - é‡è¨­ç´¢å¼•å¾Œå½¢ç‹€: {temp_df.shape}") # Removed
                    
                    df_list.append(temp_df)
            
            # ä½¿ç”¨é‡è¨­éç´¢å¼•çš„DataFrameé€²è¡Œåˆä½µ
            # st.write(f"é–‹å§‹åˆä½µ {len(df_list)} å€‹æ•¸æ“šæ¡†...") # Removed
            
            # å˜—è©¦ä½¿ç”¨ä¸åŒçš„åˆä½µæ–¹æ³•
            try:
                # æ–¹æ³•1ï¼šä½¿ç”¨concatä¸¦é¡¯å¼æŒ‡å®šignore_index
                df_combined_input = pd.concat(df_list, ignore_index=True)
                # st.write("åˆä½µæ–¹æ³•1æˆåŠŸ") # Removed
            except Exception as e1:
                st.error(f"åˆä½µæ–¹æ³•1å¤±æ•—: {e1}") # Kept error
                try:
                    # æ–¹æ³•2ï¼šé€å€‹åˆä½µ
                    df_combined_input = df_list[0].copy() if df_list else None
                    if len(df_list) > 1:
                        for i in range(1, len(df_list)):
                            df_combined_input = pd.concat([df_combined_input, df_list[i]], ignore_index=True)
                    # st.write("åˆä½µæ–¹æ³•2æˆåŠŸ") # Removed
                except Exception as e2:
                    st.error(f"åˆä½µæ–¹æ³•2å¤±æ•—: {e2}") # Kept error
                    # æ–¹æ³•3ï¼šä½¿ç”¨ç©ºDataFrameä½œç‚ºåŸºç¤é€²è¡Œåˆä½µ
                    try:
                        empty_df = pd.DataFrame()
                        df_combined_input = empty_df
                        for df in df_list:
                            df_combined_input = pd.concat([df_combined_input, df], ignore_index=True)
                        # st.write("åˆä½µæ–¹æ³•3æˆåŠŸ") # Removed
                    except Exception as e3:
                        st.error(f"æ‰€æœ‰åˆä½µæ–¹æ³•éƒ½å¤±æ•—äº†: {e3}") # Kept error
            
            # é¡¯ç¤ºåˆä½µçµæœ
            # if df_combined_input is not None: # Removed block
                # st.write(f"åˆä½µå¾Œçš„æ•¸æ“šæ¡†å½¢ç‹€: {df_combined_input.shape}") # Removed
                # st.write(f"åˆä½µå¾Œçš„æ•¸æ“šæ¡†åˆ—: {df_combined_input.columns.tolist()}") # Removed
            
            # Basic check after concat
            if df_combined_input is None or df_combined_input.empty:
                st.error("åˆä½µå¾Œçš„è³‡æ–™ç‚ºç©º")
                df_combined_input = None  # Invalidate combination
            elif 'question_position' not in df_combined_input.columns:
                st.error("åˆä½µå¾Œçš„è³‡æ–™ç¼ºå°‘ 'question_position' åˆ—")
                df_combined_input = None  # Invalidate combination
            elif df_combined_input['question_position'].isnull().any():
                st.error("åˆä½µå¾Œçš„è³‡æ–™ä¸­ 'question_position' æœ‰ç©ºå€¼")
                df_combined_input = None  # Invalidate combination
        except Exception as e:
            st.error(f"åˆä½µå·²é©—è­‰çš„è¼¸å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # é¡¯ç¤ºæ›´è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
            import traceback
            st.code(traceback.format_exc())
            df_combined_input = None

    return df_combined_input, loaded_subjects, valid_input_dfs

def display_analysis_button(df_combined_input, any_validation_errors, input_dfs, SUBJECTS):
    """Display the analysis trigger button and determine its state"""
    st.divider()
    
    all_subjects_loaded_and_valid = (len([subj for subj, df in input_dfs.items() if df is not None and subj in SUBJECTS]) == len(SUBJECTS)) and (df_combined_input is not None)
    
    # æª¢æŸ¥æ™‚é–“å£“åŠ›è©•ä¼°æ˜¯å¦å·²å¡«å¯«
    time_pressure_keys_filled = True
    missing_time_pressure_subjects = []
    for subject in SUBJECTS:
        subject_key = subject.lower()
        time_pressure_key = f"{subject_key}_time_pressure"
        if time_pressure_key not in st.session_state:
            time_pressure_keys_filled = False
            missing_time_pressure_subjects.append(subject)

    # Determine button state
    button_disabled = True
    button_message = ""

    if all_subjects_loaded_and_valid and time_pressure_keys_filled:
        button_disabled = False  # Enable button
    elif not time_pressure_keys_filled:
        button_message = f"è«‹ç‚º {'ã€'.join(missing_time_pressure_subjects)} ç§‘ç›®å¡«å¯«æ™‚é–“å£“åŠ›è©•ä¼°ï¼ˆå¿…å¡«ï¼‰ã€‚"
        st.warning(button_message, icon="âš ï¸")
    elif any_validation_errors:
        button_message = "éƒ¨åˆ†ç§‘ç›®æ•¸æ“šé©—è­‰å¤±æ•—ï¼Œè«‹ä¿®æ­£ä¸Šæ–¹æ¨™ç¤ºçš„éŒ¯èª¤å¾Œå†è©¦ã€‚"
        st.error(button_message)
    else:  # Not all subjects loaded or combined DF failed
        subjects_actually_loaded = [subj for subj, df in input_dfs.items() if df is not None and subj in SUBJECTS]
        missing_subjects = [subj for subj in SUBJECTS if subj not in subjects_actually_loaded]
        if missing_subjects:
            button_message = f"è«‹ç¢ºä¿å·²ç‚º {'ã€'.join(missing_subjects)} ç§‘ç›®æä¾›æœ‰æ•ˆæ•¸æ“šã€‚"
            st.warning(button_message, icon="âš ï¸")
        elif not input_dfs:  # No data attempted at all
            button_message = "è«‹åœ¨ä¸Šæ–¹åˆ†é ä¸­ç‚º Q, V, DI ä¸‰å€‹ç§‘ç›®ä¸Šå‚³æˆ–è²¼ä¸Šè³‡æ–™ã€‚"
            st.info(button_message)
        else:  # All attempted, but maybe combination failed or validation error cleared?
            button_message = "è«‹æª¢æŸ¥æ‰€æœ‰ç§‘ç›®çš„æ•¸æ“šæ˜¯å¦å·²æˆåŠŸåŠ è¼‰ä¸”ç„¡èª¤ã€‚"
            st.warning(button_message, icon="âš ï¸")
    
    return st.button("ğŸ” é–‹å§‹åˆ†æ", type="primary", disabled=button_disabled, key="analyze_button"), button_disabled, button_message 