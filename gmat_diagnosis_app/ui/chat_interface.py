"""
èŠå¤©ç•Œé¢æ¨¡çµ„
æä¾›AIèŠå¤©å°è©±åŠŸèƒ½
"""

import streamlit as st
from gmat_diagnosis_app.services.openai_service import get_chat_context, get_openai_response

def display_chat_interface(session_state):
    """é¡¯ç¤ºèŠå¤©ç•Œé¢ï¼Œè™•ç†è¨Šæ¯äº¤æ›"""
    st.divider()

    # Check conditions to show chat
    show_chat = check_chat_conditions(session_state)
    session_state.show_chat = show_chat

    if show_chat:
        st.header("ğŸ’¬ èˆ‡ AI å°è©± (åŸºæ–¼æœ¬æ¬¡å ±å‘Š)")

        # Display chat history
        display_chat_history(session_state)

        # Chat input at the bottom of the main page
        handle_chat_input(session_state)
        
def check_chat_conditions(session_state):
    """æª¢æŸ¥æ˜¯å¦æ»¿è¶³é¡¯ç¤ºèŠå¤©çš„æ¢ä»¶"""
    if session_state.openai_api_key and session_state.diagnosis_complete:
        return True
    return False

def display_chat_history(session_state):
    """é¡¯ç¤ºèŠå¤©æ­·å²"""
    for message in session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

def handle_chat_input(session_state):
    """è™•ç†ç”¨æˆ¶è¼¸å…¥å’ŒAIå›æ‡‰"""
    if prompt := st.chat_input("é‡å°å ±å‘Šå’Œæ•¸æ“šæå•..."):
        # Add user message to history and display
        session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Prepare context and call OpenAI
        with st.chat_message("assistant"):
            message_placeholder = st.empty()  # Placeholder for streaming or waiting message
            message_placeholder.markdown("æ€è€ƒä¸­...")
            try:
                # Get context
                context = get_chat_context(session_state)
                
                # Call OpenAI
                ai_response_text, response_id = get_openai_response(
                    session_state.chat_history,
                    context["report"],
                    context["dataframe"],
                    session_state.openai_api_key
                )

                # Display AI response and add to history with response_id
                message_placeholder.markdown(ai_response_text)
                session_state.chat_history.append({
                    "role": "assistant",
                    "content": ai_response_text,
                    "response_id": response_id  # Store the ID for the next turn
                })

            except Exception as e:
                error_message = f"å‘¼å« AI æ™‚å‡ºéŒ¯: {e}"
                message_placeholder.error(error_message)
                # Add error message to history, without a response_id
                session_state.chat_history.append({"role": "assistant", "content": error_message}) 